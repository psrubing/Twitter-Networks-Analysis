{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9ef5fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "import torch\n",
    "from transformers import __version__ as transformers_version\n",
    "from torch import __version__ as torch_version\n",
    "\n",
    "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "caa78054",
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_accounts_path = r'C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2'\n",
    "hand_picked_new_anti_hubs_path = r'C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs'\n",
    "\n",
    "pro_accounts_path = r'C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2'\n",
    "hand_picked_new_pro_hubs_path = r'C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs'\n",
    "\n",
    "neutral_accounts_path = r'C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433620c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_accounts = os.listdir(anti_accounts_path)\n",
    "hand_picked_new_anti_hubs = os.listdir(hand_picked_new_anti_hubs_path)\n",
    "\n",
    "pro_accounts = os.listdir(pro_accounts_path)\n",
    "hand_picked_new_pro_hubs = os.listdir(hand_picked_new_pro_hubs_path)\n",
    "\n",
    "neutral_accounts = os.listdir(neutral_accounts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2147d02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@5gAwareness\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@5GAwarenessNow\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@5gDangers\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@AlternMedicine1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@AMGuide\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Anastas32451695\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@AncestralApoth\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@AnnleeElisha\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@avoiceforchoice\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@BusyDrT\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@CAchemtrails\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@CaliVaxChoice\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Canoe_Glider\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@CHEMTRAILSMN\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@ChemtrailsNews\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Chemtrails_UK\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@circleofmamas\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@delbigtree\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DinosaurEarth\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@dmarble\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DrBenTapper1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DrButtar\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DrChrisNorthrup\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DrMadej\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DrSamBenjamin\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@drsimonegold\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DSL1912\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@earthisaplane7\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@ehs_symptoms\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@EMFAustralia\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@EMFRebel\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@EndTheGlobe\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@facebones777\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatArthur\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatAwakening\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@flatearthaddict\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthBaba\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthCity\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthEffect\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@flatearthohio\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthOrg\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthRT\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthTshirt\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatRealm\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatSmacker\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@flat_earth_dude\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@flat_its\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@forcedanarchy\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@forrestmaready\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@GlobalCHEMTRAIL\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@GMOFreeUSA\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Gylauer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@HegKong\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@heru41\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@hhnews\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@hidenhand1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@HighWireTalk\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@hollyhaygood\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@itsBentooLong\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Its_Stationary\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@JakeMaverick5\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@JasminMartino\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@jrickerthall\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@JustWakeUp8\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@keepit1002018\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@kellybroganmd\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@KenzoAmariyo\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@kevdjenkins1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@KimShute_NY\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Knowfree77\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@LaurenceBacchus\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@laurencette\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@lifebiomedguru\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@LookTheFuckUp_\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Lumineuse72\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@MakimuraYusaku\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@MargoCatholic\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@MedicineAlt\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@mercola\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@MyLindseyMcKeon\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@natural4healing\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@naturalhealthbl\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@NickHudsonCT\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@nickworldclass\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@nocompulsoryvac\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Novaccineforce\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@octoberxswimmer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@onthechemtrail\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@OpChemtrails\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@OrganicConsumer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@PdxTreehouse\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@proventreatment\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@QMFlatEarth\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@radiation_uk\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@radzzzzster\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@richaelfaithful\\tweets.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@ritamollerpalma\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@riteaid\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@RobertKennedyJr\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@sayerjigmi\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Scotland5g\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Spacehehehe\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Stop5G\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@STOP5G_STOP5G\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@SydneyChemtrail\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@TheFlatEartherr\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@TomSoenen1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@truthvaxwarrior\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@unhealthytruth\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@US4MF\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@VaccineEdLeague\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@VaccineResist\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@VAware1986\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@VaxFactsCA\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@vaxxed2\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@VitalityOnline\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Vomit911\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@wanderinganimal\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@wddty\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@WeWillBeFree82\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@WorldwideHealth\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@yattypat\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@YouthAgainst5G\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@_CSHD\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\TNaturalHealing\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\82jsmith\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\apiscesdream\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\Astroidhalo774\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\authoralexray\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\barmanamar1976\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\BBGRichie\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\CarlDevitt\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\Cernovich\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\Chemtrails_Uk\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\ChildrensHD\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\cuttingchains\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\DavidWolfe\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\derek99white191\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\dmarble1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\drbloem\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\DrJudyAMikovits\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\EarthIsFlat1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\earthisflat87\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\elonmusk\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\faith4truths\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\FEcourious\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\FlatEarthFreddy\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\flatearthling\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\Homestead4Honey\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\IngrahamAngle\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\ItsFlatFolks\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\JeffereyJaxen\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\jeranism\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\jonrappoport\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\LaLaRueFrench75\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\LeeZilch\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\MaxisicalG\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\mend_the_world\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\NASA\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\NikonP1111\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\nocurvature\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\NothingSirius\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\NotPorC\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\oddtv3\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\ParisUsa333\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\picphysicians\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\PrisonPlanet\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\RichardReichle\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\RobSchneider\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\rsbellmedia\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\RyaanFEP\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\screwnasapunks\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\SeekingTruth___\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\SlayckPhoenix\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\Tierraplana6\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\Trilluminarian\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\tsnurds\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\UnlearningLies\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\WeAreWakinUp\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\zeteticmisophia\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_anti_hubs\\zorommot\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@2020science\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@AmyMainzer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@Atul_Gawande\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@BadAstronomer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@bengoldacre\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@bgreene\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@carolynporco\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@danariely\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@danlevitin\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@DanTGilbert\\tweets.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@deborahblum\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@dgmacarthur\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@DrVes\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@edyong209\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@EricTopol\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@HansRosling\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@JCVenter\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@JFGariepy\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@JohnAllenPaulos\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@kejames\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@kinggary\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@LabSpaces\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@LKrauss1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@MarcusduSautoy\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@mbeisen\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@MichaelEMann\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@michiokaku\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@neiltyson\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@neuroconscience\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@OliverSacks\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@orbitingfrog\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@paulbloomatyale\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@phylogenomics\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@plutokiller\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@ProfBrianCox\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@ProfRWinston\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@pzmyers\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@RandomSpaceFact\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@RebeccaSkloot\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@RichardDawkins\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@RichardWiseman\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@SamHarrisOrg\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@sapinker\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@sbaroncohen\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@seanmcarroll\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@SebastianThrun\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@SethShostak\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@social_brains\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@starstryder\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@timberners_lee\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@vaughanbell\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\AdamRutherford\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\aetiology\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\alexismadrigal\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\amy_harmon\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\AstroKatie\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\BeeBrookshire\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\BillGates\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\BillNye\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\bmaher\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\carlzimmer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\chriscmooney\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\CT_Bergstrom\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\danieldennett\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\davideagleman\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\David_Dobbs\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\DNLee5\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\drkiki\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\edge\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\elakdawalla\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\elonmusk\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\JenLucPiquant\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\KamalaHarris\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\leonidkruglyak\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\maggiekb1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\MarsCuriosity\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\marynmck\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\matthewherper\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\mdichristina\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\michaelshermer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\mollycrockett\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\NAChristakis\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\NASA\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\NateSilver538\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\NYTScience\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\rebeccawatson\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\sciam\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\sciencegoddess\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\ScienceMagazine\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\scifri\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\SpaceX\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\stevenstrogatz\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\TEDchris\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\utafrith\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\virginiahughes\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\hand_picked_new_pro_hubs\\zeynep\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\acsifferlin\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\ActuallyNPH\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\Adele\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\AnnaKendrick47\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\bittman\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\BrunoMars\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\carlreinerl\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\chaerincaps\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\cocorocha\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\ConanOBrien\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\CraigyFerg\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\Cristiano\\tweets.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\DalaiLama\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\deepikapadukone\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\dnatatravel\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\drsanjaygupta\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\EmmaWatson\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\ETTravelNews\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\FiTravels\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\imVkohli\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\JJainchillTW\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\JoeBiden\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\jtimberlake\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\judyblume\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\kanyewest\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\kellyoxford\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\LaurenHoTravels\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\LilTunechi\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\LuxTravel\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\marionnestle\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\McKaylaMaroney\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\mollymcnearney\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\nickbilton\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\Pontifex\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\sachin_rt\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\Sartorialist\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\she_travels\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\Shteyngart\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\simondoonan\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\statsCL_twt\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\StephenKing\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\SteveMartinToGo\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\taylorswift13\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\TheRealStanLee\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\thesulk\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\TimTebow\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\travel88888\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\trending\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\yassir_lester\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\neutral_data_1\\zefrank\\tweets.json\n"
     ]
    }
   ],
   "source": [
    "# ANTI BASE\n",
    "tweets_dfs = []\n",
    "for account in anti_accounts:\n",
    "    acc_path = os.path.join(anti_accounts_path, account)\n",
    "    try: \n",
    "        print(os.path.join(acc_path, 'tweets.json'))\n",
    "        df = pd.read_json(os.path.join(acc_path, 'tweets.json'))\n",
    "        df['account'] = account\n",
    "        tweets_dfs.append(df)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "# ANTI NEW\n",
    "for account in hand_picked_new_anti_hubs:\n",
    "    acc_path = os.path.join(hand_picked_new_anti_hubs_path, account)\n",
    "    try: \n",
    "        print(os.path.join(acc_path, 'tweets.json'))\n",
    "        df = pd.read_json(os.path.join(acc_path, 'tweets.json'))\n",
    "        df['account'] = account\n",
    "        tweets_dfs.append(df)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "anti_df = pd.concat(tweets_dfs, ignore_index=True)\n",
    "anti_df['class'] = 0\n",
    "\n",
    "\n",
    "# PRO BASE\n",
    "tweets_dfs = []\n",
    "for account in pro_accounts:\n",
    "    acc_path = os.path.join(pro_accounts_path, account)\n",
    "    try: \n",
    "        print(os.path.join(acc_path, 'tweets.json'))\n",
    "        df = pd.read_json(os.path.join(acc_path, 'tweets.json'))\n",
    "        df['account'] = account\n",
    "        tweets_dfs.append(df)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "# PRO NEW\n",
    "for account in hand_picked_new_pro_hubs:\n",
    "    acc_path = os.path.join(hand_picked_new_pro_hubs_path, account)\n",
    "    try: \n",
    "        print(os.path.join(acc_path, 'tweets.json'))\n",
    "        df = pd.read_json(os.path.join(acc_path, 'tweets.json'))\n",
    "        df['account'] = account\n",
    "        tweets_dfs.append(df)\n",
    "    except ValueError:\n",
    "        continue\n",
    "        \n",
    "pro_df = pd.concat(tweets_dfs, ignore_index=True)\n",
    "pro_df['class'] = 2\n",
    "\n",
    "\n",
    "tweets_dfs = []\n",
    "for account in neutral_accounts:\n",
    "    acc_path = os.path.join(neutral_accounts_path, account)\n",
    "    try: \n",
    "        print(os.path.join(acc_path, 'tweets.json'))\n",
    "        df = pd.read_json(os.path.join(acc_path, 'tweets.json'))\n",
    "        df['account'] = account\n",
    "        tweets_dfs.append(df)\n",
    "    except ValueError:\n",
    "        continue\n",
    "        \n",
    "neutral_df = pd.concat(tweets_dfs, ignore_index=True)\n",
    "neutral_df['class'] = 1\n",
    "\n",
    "df = pd.concat([anti_df, pro_df, neutral_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b98b3791",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b02c7c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filtered_text'] = df['clean_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in english_stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f15d42da",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_text = df.groupby(['account', 'class'], as_index = False).agg({'filtered_text': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e48731",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e74a2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')\n",
    "#device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0432a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40416028",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3559b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    preds = np.argmax(predictions, axis=-1)\n",
    "    \n",
    "    return {'Accuracy': accuracy_score(labels, preds),\n",
    "           'Precision': precision_score(labels, preds, average='weighted'),\n",
    "           'Recall': recall_score(labels, preds, average='weighted'),\n",
    "           'f1': f1_score(labels, preds, average='weighted')}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06f91017",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='sentiment'\n",
    "model_name = f\"cardiffnlp/twitter-roberta-base-{task}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82f7c669",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92507cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2b1d60ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_grouped_text, test_size=0.2, random_state=1)\n",
    "train, valid = train_test_split(train, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8537cef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(220, 3) (25, 3) (62, 3)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape, valid.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80a328b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train['filtered_text'].tolist(), truncation=True, max_length=512, padding=True, return_tensors='pt')\n",
    "val_encodings = tokenizer(valid['filtered_text'].tolist(), truncation=True, max_length=512, padding=True, return_tensors='pt')\n",
    "test_encodings = tokenizer(test['filtered_text'].tolist(), truncation=True, max_length=512, padding=True, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89a66eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(train_encodings, train['class'].tolist())\n",
    "val_dataset = CustomDataset(val_encodings, valid['class'].tolist())\n",
    "test_dataset = CustomDataset(test_encodings, test['class'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27fea114",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "output_dir = r'C:\\Users\\psrub\\Documents\\Python\\Twitter\\models\\bert_finetuned'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9cff4595",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(output_dir=r'C:\\Users\\psrub\\Documents\\Python\\Twitter\\models\\results',\n",
    "                                 num_train_epochs=8, per_device_train_batch_size=batch_size, per_device_eval_batch_size=batch_size,\n",
    "                                 warmup_steps=500, weight_decay=0.01, logging_dir=r'C:\\Users\\psrub\\Documents\\Python\\Twitter\\models\\logs',\n",
    "                                  logging_steps=10, save_total_limit=4, evaluation_strategy='epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e7022ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=val_dataset, compute_metrics=compute_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "416666da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 220\n",
      "  Num Epochs = 8\n",
      "  Instantaneous batch size per device = 2\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 2\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 880\n",
      "<ipython-input-11-b3a726fd78a3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='880' max='880' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [880/880 05:21, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.850100</td>\n",
       "      <td>1.311235</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.516491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.404000</td>\n",
       "      <td>0.964973</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.628571</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.654000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.411500</td>\n",
       "      <td>2.354495</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.550476</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.577000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.153100</td>\n",
       "      <td>1.248271</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.649231</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.694545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.652400</td>\n",
       "      <td>0.777600</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.653824</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.693712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.349900</td>\n",
       "      <td>1.037312</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.697143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.767100</td>\n",
       "      <td>0.923383</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.653824</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.693712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.611600</td>\n",
       "      <td>0.953393</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>0.691429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 2\n",
      "C:\\Users\\psrub\\anaconda3\\envs\\Twitter\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-11-b3a726fd78a3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 2\n",
      "C:\\Users\\psrub\\anaconda3\\envs\\Twitter\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-11-b3a726fd78a3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 2\n",
      "C:\\Users\\psrub\\anaconda3\\envs\\Twitter\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-11-b3a726fd78a3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 2\n",
      "C:\\Users\\psrub\\anaconda3\\envs\\Twitter\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-11-b3a726fd78a3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Saving model checkpoint to C:\\Users\\psrub\\Documents\\Python\\Twitter\\models\\results\\checkpoint-500\n",
      "Configuration saved in C:\\Users\\psrub\\Documents\\Python\\Twitter\\models\\results\\checkpoint-500\\config.json\n",
      "Model weights saved in C:\\Users\\psrub\\Documents\\Python\\Twitter\\models\\results\\checkpoint-500\\pytorch_model.bin\n",
      "<ipython-input-11-b3a726fd78a3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 2\n",
      "C:\\Users\\psrub\\anaconda3\\envs\\Twitter\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-11-b3a726fd78a3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 2\n",
      "C:\\Users\\psrub\\anaconda3\\envs\\Twitter\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-11-b3a726fd78a3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 2\n",
      "C:\\Users\\psrub\\anaconda3\\envs\\Twitter\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "<ipython-input-11-b3a726fd78a3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 25\n",
      "  Batch size = 2\n",
      "C:\\Users\\psrub\\anaconda3\\envs\\Twitter\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=880, training_loss=0.9589677904139865, metrics={'train_runtime': 323.4849, 'train_samples_per_second': 5.441, 'train_steps_per_second': 2.72, 'total_flos': 463079615201280.0, 'train_loss': 0.9589677904139865, 'epoch': 8.0})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "13b25cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to C:\\Users\\psrub\\Documents\\Python\\Twitter\\models\\bert_finetuned\n",
      "Configuration saved in C:\\Users\\psrub\\Documents\\Python\\Twitter\\models\\bert_finetuned\\config.json\n",
      "Model weights saved in C:\\Users\\psrub\\Documents\\Python\\Twitter\\models\\bert_finetuned\\pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.save_model(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24303110",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "95c1b3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 62\n",
      "  Batch size = 2\n",
      "<ipython-input-11-b3a726fd78a3>:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psrub\\anaconda3\\envs\\Twitter\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "preds = trainer.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b01f0434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'test_loss': 1.1981016397476196,\n",
       " 'test_Accuracy': 0.6774193548387096,\n",
       " 'test_Precision': 0.5488911290322581,\n",
       " 'test_Recall': 0.6774193548387096,\n",
       " 'test_f1': 0.5934825543120474,\n",
       " 'test_runtime': 2.8883,\n",
       " 'test_samples_per_second': 21.466,\n",
       " 'test_steps_per_second': 10.733}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c29df47f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 0, 2, 1, 1, 1, 0, 0, 0, 2, 1, 0, 1, 2, 0, 0, 0, 0, 2,\n",
       "       0, 1, 2, 2, 0, 1, 2, 0, 1, 0, 0, 0, 0, 0, 2, 2, 1, 2, 1, 1, 1, 0,\n",
       "       0, 2, 2, 1, 0, 1, 0, 2, 0, 0, 0, 0, 2, 1, 0, 0, 2, 2], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d5732814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.560338  , -0.7263268 ,  2.3910112 ],\n",
       "       [ 4.469163  , -2.3109488 , -2.4064472 ],\n",
       "       [-1.5630574 , -0.7266832 ,  2.3929706 ],\n",
       "       [ 4.469802  , -2.3109672 , -2.4063535 ],\n",
       "       [ 4.452751  , -2.2859535 , -2.404729  ],\n",
       "       [-1.5631062 , -0.72670084,  2.39302   ],\n",
       "       [ 3.3547807 , -1.520161  , -1.9494908 ],\n",
       "       [ 0.9365221 , -0.30674702, -0.49381807],\n",
       "       [-1.5620872 , -0.7266271 ,  2.3924334 ],\n",
       "       [ 3.7325916 , -1.8736285 , -1.9438835 ],\n",
       "       [ 4.463103  , -2.299201  , -2.4047537 ],\n",
       "       [ 4.433906  , -2.2692018 , -2.4016213 ],\n",
       "       [-1.5625608 , -0.72662586,  2.3927104 ],\n",
       "       [-1.4021856 , -0.70756197,  2.2915735 ],\n",
       "       [ 4.458393  , -2.2977664 , -2.4035454 ],\n",
       "       [-1.5625569 , -0.7266013 ,  2.3926387 ],\n",
       "       [-1.5628155 , -0.72663087,  2.3928144 ],\n",
       "       [ 4.4624443 , -2.302332  , -2.4061456 ],\n",
       "       [ 4.446     , -2.284699  , -2.403836  ],\n",
       "       [ 4.4653673 , -2.3031142 , -2.4058533 ],\n",
       "       [ 4.4660416 , -2.306872  , -2.4051766 ],\n",
       "       [-1.562536  , -0.7266052 ,  2.3926685 ],\n",
       "       [-1.5630398 , -0.7267014 ,  2.3930132 ],\n",
       "       [-1.5627817 , -0.7266475 ,  2.3928392 ],\n",
       "       [-1.5627874 , -0.7266258 ,  2.3927977 ],\n",
       "       [-1.5584724 , -0.7264562 ,  2.3895192 ],\n",
       "       [ 4.457398  , -2.2978334 , -2.4012    ],\n",
       "       [-1.5626181 , -0.7266277 ,  2.3927538 ],\n",
       "       [-1.5626287 , -0.72660065,  2.3927085 ],\n",
       "       [ 4.4702983 , -2.3088195 , -2.405887  ],\n",
       "       [ 4.4177356 , -2.2498744 , -2.3996975 ],\n",
       "       [ 4.4464917 , -2.284785  , -2.3989122 ],\n",
       "       [-1.5631707 , -0.72670996,  2.3930504 ],\n",
       "       [ 4.4474745 , -2.279854  , -2.413622  ],\n",
       "       [ 4.4556346 , -2.2948515 , -2.4027176 ],\n",
       "       [ 4.471967  , -2.3124497 , -2.406756  ],\n",
       "       [-1.5628648 , -0.72664464,  2.3928492 ],\n",
       "       [-1.562853  , -0.7266368 ,  2.3928795 ],\n",
       "       [ 0.36966246, -0.38987887,  0.04294581],\n",
       "       [-1.5626003 , -0.72661805,  2.3927023 ],\n",
       "       [-1.5627118 , -0.726622  ,  2.3927839 ],\n",
       "       [ 4.404255  , -2.2373734 , -2.3868096 ],\n",
       "       [-1.5485048 , -0.72267914,  2.3757555 ],\n",
       "       [ 4.4647784 , -2.3056545 , -2.4060621 ],\n",
       "       [ 4.461797  , -2.301661  , -2.405138  ],\n",
       "       [-1.4780595 , -0.7036351 ,  2.3158736 ],\n",
       "       [-1.5630956 , -0.7266819 ,  2.393006  ],\n",
       "       [-1.5615    , -0.7265654 ,  2.392066  ],\n",
       "       [ 4.461754  , -2.3011298 , -2.4058685 ],\n",
       "       [-1.5628668 , -0.7266332 ,  2.3928573 ],\n",
       "       [ 4.464101  , -2.301577  , -2.405048  ],\n",
       "       [-1.5632323 , -0.72668195,  2.3930583 ],\n",
       "       [-1.562741  , -0.72665954,  2.3927872 ],\n",
       "       [ 4.327561  , -2.1592276 , -2.3762913 ],\n",
       "       [-1.561789  , -0.72662896,  2.3921988 ],\n",
       "       [ 4.455395  , -2.2974944 , -2.4008741 ],\n",
       "       [-1.5632232 , -0.72669953,  2.3930736 ],\n",
       "       [-1.5630301 , -0.7266673 ,  2.3929398 ],\n",
       "       [ 4.4518723 , -2.2930875 , -2.402035  ],\n",
       "       [ 4.454995  , -2.2958097 , -2.4042034 ],\n",
       "       [-1.5618898 , -0.726568  ,  2.3922744 ],\n",
       "       [-1.5614748 , -0.72658116,  2.3920953 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31554606",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.memory_summary(device=None, abbreviated=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431a274b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd15b68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c146f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234b5133",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e83696",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model = r'C:\\Users\\psrub\\Documents\\Python\\Twitter\\models\\finetuned_bert'\n",
    "model = AutoModelForSequenceClassification.from_pretrained(finetuned_model,local_files_only=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a47aad20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import sigmoid\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6320ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00bba77",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, tokenizer, model):\n",
    "    encoded = tokenizer(text, truncation=True, max_length=512, padding=True, return_tensors='pt').to(device)\n",
    "    model_output = model(**encoded)\n",
    "    \n",
    "    return sigmoid(model_output.logits)[0].cpu().detach().numpy()\n",
    "\n",
    "def predict_batch(texts, tokenizer, model):\n",
    "    return [predict(text, tokenizer, model) for text in texts]\n",
    "\n",
    "def predict_hf(text, tokenizer, model):\n",
    "\n",
    "    encoded_input = tokenizer(text, truncation=True, padding=True, max_length=512, return_tensors='pt').to(device)\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].cpu().detach().numpy()\n",
    "    return softmax(scores)\n",
    "\n",
    "def predict_batch_hf(texts, tokenizer, model):\n",
    "    return [predict(text, tokenizer, model) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb8f0f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(result, labels):\n",
    "    ranking = np.argsort(result)\n",
    "    ranking = ranking[::-1]\n",
    "\n",
    "    for i in range(result.shape[0]):\n",
    "        l = labels[ranking[i]]\n",
    "        s = result[ranking[i]]\n",
    "        print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ed819a",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_grouped_text['filtered_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c845b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict_batch(texts, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9de120",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([r.tolist() for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f939c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['prediction'] = np.argmax(results_df[[0, 1, 2]].to_numpy(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9a8962",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d01d52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_text['prediction'] = results_df['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd68020",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e10a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y = df_grouped_text['class']\n",
    "pred_y = df_grouped_text['prediction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8d4ff2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(true_y, pred_y))\n",
    "print(confusion_matrix(true_y, pred_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890b0f95",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
