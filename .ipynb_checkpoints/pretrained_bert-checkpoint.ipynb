{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fbf0bfe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import urllib.request\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4a2b414",
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_accounts_path = r'C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2'\n",
    "pro_accounts_path = r'C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f55e0674",
   "metadata": {},
   "outputs": [],
   "source": [
    "anti_accounts = os.listdir(anti_accounts_path)\n",
    "pro_accounts = os.listdir(pro_accounts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "395454a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@5gAwareness\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@5GAwarenessNow\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@5gDangers\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@AlternMedicine1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@AMGuide\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Anastas32451695\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@AncestralApoth\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@AnnleeElisha\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@avoiceforchoice\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@BusyDrT\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@CAchemtrails\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@CaliVaxChoice\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Canoe_Glider\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@CHEMTRAILSMN\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@ChemtrailsNews\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Chemtrails_UK\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@circleofmamas\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@delbigtree\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DinosaurEarth\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@dmarble\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DrBenTapper1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DrButtar\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DrChrisNorthrup\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DrMadej\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DrSamBenjamin\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@drsimonegold\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@DSL1912\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@earthisaplane7\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@ehs_symptoms\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@EMFAustralia\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@EMFRebel\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@EndTheGlobe\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@facebones777\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatArthur\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatAwakening\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@flatearthaddict\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthBaba\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthCity\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthEffect\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@flatearthohio\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthOrg\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthRT\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatEarthTshirt\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatRealm\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@FlatSmacker\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@flat_earth_dude\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@flat_its\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@forcedanarchy\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@forrestmaready\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@GlobalCHEMTRAIL\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@GMOFreeUSA\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Gylauer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@HegKong\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@heru41\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@hhnews\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@hidenhand1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@HighWireTalk\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@hollyhaygood\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@itsBentooLong\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Its_Stationary\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@JakeMaverick5\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@JasminMartino\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@jrickerthall\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@JustWakeUp8\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@keepit1002018\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@kellybroganmd\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@KenzoAmariyo\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@kevdjenkins1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@KimShute_NY\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Knowfree77\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@LaurenceBacchus\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@laurencette\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@lifebiomedguru\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@LookTheFuckUp_\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Lumineuse72\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@MakimuraYusaku\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@MargoCatholic\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@MedicineAlt\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@mercola\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@MyLindseyMcKeon\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@natural4healing\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@naturalhealthbl\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@NickHudsonCT\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@nickworldclass\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@nocompulsoryvac\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Novaccineforce\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@octoberxswimmer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@onthechemtrail\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@OpChemtrails\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@OrganicConsumer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@PdxTreehouse\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@proventreatment\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@QMFlatEarth\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@radiation_uk\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@radzzzzster\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@richaelfaithful\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@ritamollerpalma\\tweets.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@riteaid\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@RobertKennedyJr\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@sayerjigmi\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Scotland5g\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Spacehehehe\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Stop5G\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@STOP5G_STOP5G\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@SydneyChemtrail\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@TheFlatEartherr\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@TomSoenen1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@truthvaxwarrior\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@unhealthytruth\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@US4MF\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@VaccineEdLeague\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@VaccineResist\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@VAware1986\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@VaxFactsCA\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@vaxxed2\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@VitalityOnline\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@Vomit911\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@wanderinganimal\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@wddty\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@WeWillBeFree82\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@WorldwideHealth\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@yattypat\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@YouthAgainst5G\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\@_CSHD\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\anti_scientific_data_2\\TNaturalHealing\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@2020science\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@AmyMainzer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@Atul_Gawande\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@BadAstronomer\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@bengoldacre\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@bgreene\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@carolynporco\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@danariely\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@danlevitin\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@DanTGilbert\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@deborahblum\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@dgmacarthur\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@DrVes\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@edyong209\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@EricTopol\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@HansRosling\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@JCVenter\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@JFGariepy\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@JohnAllenPaulos\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@kejames\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@kinggary\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@LabSpaces\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@LKrauss1\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@MarcusduSautoy\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@mbeisen\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@MichaelEMann\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@michiokaku\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@neiltyson\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@neuroconscience\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@OliverSacks\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@orbitingfrog\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@paulbloomatyale\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@phylogenomics\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@plutokiller\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@ProfBrianCox\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@ProfRWinston\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@pzmyers\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@RandomSpaceFact\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@RebeccaSkloot\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@RichardDawkins\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@RichardWiseman\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@SamHarrisOrg\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@sapinker\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@sbaroncohen\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@seanmcarroll\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@SebastianThrun\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@SethShostak\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@social_brains\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@starstryder\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@timberners_lee\\tweets.json\n",
      "C:\\Users\\psrub\\Documents\\Python\\Twitter\\pro_scientific_data_2\\@vaughanbell\\tweets.json\n"
     ]
    }
   ],
   "source": [
    "tweets_dfs = []\n",
    "\n",
    "for account in anti_accounts:\n",
    "    acc_path = os.path.join(anti_accounts_path, account)\n",
    "    try: \n",
    "        print(os.path.join(acc_path, 'tweets.json'))\n",
    "        df = pd.read_json(os.path.join(acc_path, 'tweets.json'))\n",
    "        df['account'] = account\n",
    "        tweets_dfs.append(df)\n",
    "    except ValueError:\n",
    "        continue\n",
    "\n",
    "anti_df = pd.concat(tweets_dfs, ignore_index=True)\n",
    "anti_df['class'] = 1\n",
    "\n",
    "tweets_dfs = []\n",
    "        \n",
    "for account in pro_accounts:\n",
    "    acc_path = os.path.join(pro_accounts_path, account)\n",
    "    try: \n",
    "        print(os.path.join(acc_path, 'tweets.json'))\n",
    "        df = pd.read_json(os.path.join(acc_path, 'tweets.json'))\n",
    "        df['account'] = account\n",
    "        tweets_dfs.append(df)\n",
    "    except ValueError:\n",
    "        continue\n",
    "        \n",
    "pro_df = pd.concat(tweets_dfs, ignore_index=True)\n",
    "pro_df['class'] = 0\n",
    "\n",
    "df = pd.concat([anti_df, pro_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c1d2766",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stopwords = stopwords.words(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a264a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['filtered_text'] = df['clean_text'].apply(lambda x: ' '.join([word for word in x.split() if word not in english_stopwords]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67491618",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped_text = df.groupby(['account', 'class'], as_index = False).agg({'filtered_text': ' '.join})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b67a8a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>class</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@2020science</td>\n",
       "      <td>0</td>\n",
       "      <td>Have reached peak produce labeling?! Congrats ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@5GAwarenessNow</td>\n",
       "      <td>1</td>\n",
       "      <td>shes hot too. matter...but matters _FTW ZING! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@5gAwareness</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh like masonic father locked hilary? Oops!! I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@5gDangers</td>\n",
       "      <td>1</td>\n",
       "      <td>What us look real climate science known long t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@AlternMedicine1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colombian Insurance Providers Required To Cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>@vaxxed2</td>\n",
       "      <td>1</td>\n",
       "      <td>Make sure go website sign email list join tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>@wanderinganimal</td>\n",
       "      <td>1</td>\n",
       "      <td>_ 1 But read tweets talking unresearched Georg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>@wddty</td>\n",
       "      <td>1</td>\n",
       "      <td>Air pollution could big factor influences seve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>@yattypat</td>\n",
       "      <td>1</td>\n",
       "      <td>_says _ukulele And suicides? Fatal car acciden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>TNaturalHealing</td>\n",
       "      <td>1</td>\n",
       "      <td>_sarig You guys better crush earnings Nov 8th ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              account  class  \\\n",
       "0        @2020science      0   \n",
       "1     @5GAwarenessNow      1   \n",
       "2        @5gAwareness      1   \n",
       "3          @5gDangers      1   \n",
       "4    @AlternMedicine1      1   \n",
       "..                ...    ...   \n",
       "156          @vaxxed2      1   \n",
       "157  @wanderinganimal      1   \n",
       "158            @wddty      1   \n",
       "159         @yattypat      1   \n",
       "160   TNaturalHealing      1   \n",
       "\n",
       "                                         filtered_text  \n",
       "0    Have reached peak produce labeling?! Congrats ...  \n",
       "1    shes hot too. matter...but matters _FTW ZING! ...  \n",
       "2    Oh like masonic father locked hilary? Oops!! I...  \n",
       "3    What us look real climate science known long t...  \n",
       "4    Colombian Insurance Providers Required To Cove...  \n",
       "..                                                 ...  \n",
       "156  Make sure go website sign email list join tele...  \n",
       "157  _ 1 But read tweets talking unresearched Georg...  \n",
       "158  Air pollution could big factor influences seve...  \n",
       "159  _says _ukulele And suicides? Fatal car acciden...  \n",
       "160  _sarig You guys better crush earnings Nov 8th ...  \n",
       "\n",
       "[161 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5673cb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e7a5a66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 23 14:53:15 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 497.29       Driver Version: 497.29       CUDA Version: 11.5     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0  On |                  N/A |\n",
      "| 27%   57C    P0    33W / 120W |    522MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      3480    C+G   ...nputApp\\TextInputHost.exe    N/A      |\n",
      "|    0   N/A  N/A      5980    C+G   ...cw5n1h2txyewy\\LockApp.exe    N/A      |\n",
      "|    0   N/A  N/A     11200    C+G   Insufficient Permissions        N/A      |\n",
      "|    0   N/A  N/A     11656    C+G   ...perience\\NVIDIA Share.exe    N/A      |\n",
      "|    0   N/A  N/A     50756    C+G   C:\\Windows\\explorer.exe         N/A      |\n",
      "|    0   N/A  N/A     80700    C+G   ...5n1h2txyewy\\SearchApp.exe    N/A      |\n",
      "|    0   N/A  N/A     82796    C+G   ...me\\Application\\chrome.exe    N/A      |\n",
      "|    0   N/A  N/A     84652    C+G   ...y\\ShellExperienceHost.exe    N/A      |\n",
      "|    0   N/A  N/A     87104    C+G   ...bbwe\\Microsoft.Photos.exe    N/A      |\n",
      "|    0   N/A  N/A     91212    C+G   ...ekyb3d8bbwe\\YourPhone.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9f5ea9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import __version__ as transformers_version\n",
    "from torch import __version__ as torch_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef56671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a24aca27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276c6e00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31a5f8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c204c719",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8dfb642",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['negative', 'neutral', 'positive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7514c615",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8f6fe61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8ad69c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import sigmoid\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "78c3e7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, tokenizer, model):\n",
    "    encoded = tokenizer(text, truncation=True, max_length=512, padding=True, return_tensors='pt').to(device)\n",
    "    model_output = model(**encoded)\n",
    "    \n",
    "    return sigmoid(model_output.logits)[0].cpu().detach().numpy()\n",
    "\n",
    "def predict_batch(texts, tokenizer, model):\n",
    "    return [predict(text, tokenizer, model) for text in texts]\n",
    "\n",
    "def predict_hf(text, tokenizer, model):\n",
    "\n",
    "    encoded_input = tokenizer(text, truncation=True, padding=True, max_length=512, return_tensors='pt').to(device)\n",
    "    output = model(**encoded_input)\n",
    "    scores = output[0][0].cpu().detach().numpy()\n",
    "    return softmax(scores)\n",
    "\n",
    "def predict_batch_hf(texts, tokenizer, model):\n",
    "    return [predict(text, tokenizer, model) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3701a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(result, labels):\n",
    "    ranking = np.argsort(result)\n",
    "    ranking = ranking[::-1]\n",
    "\n",
    "    for i in range(result.shape[0]):\n",
    "        l = labels[ranking[i]]\n",
    "        s = result[ranking[i]]\n",
    "        print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "dd65219d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pro0 = df_grouped_text.iloc[0]['filtered_text']\n",
    "anti0 = df_grouped_text.iloc[1]['filtered_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4f716539",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8913398 , 0.5082953 , 0.08866754], dtype=float32)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = predict(anti0, tokenizer, model)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ae72794c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.8788267 , 0.11074962, 0.01042361], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_hf = predict_hf(anti0, tokenizer, model)\n",
    "res_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8a477633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) negative 0.8913\n",
      "2) neutral 0.5083\n",
      "3) positive 0.0887\n"
     ]
    }
   ],
   "source": [
    "print_results(res, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "63e34b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1) negative 0.8788\n",
      "2) neutral 0.1107\n",
      "3) positive 0.0104\n"
     ]
    }
   ],
   "source": [
    "print_results(res_hf, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6104a5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>class</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@2020science</td>\n",
       "      <td>0</td>\n",
       "      <td>Have reached peak produce labeling?! Congrats ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@5GAwarenessNow</td>\n",
       "      <td>1</td>\n",
       "      <td>shes hot too. matter...but matters _FTW ZING! ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@5gAwareness</td>\n",
       "      <td>1</td>\n",
       "      <td>Oh like masonic father locked hilary? Oops!! I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@5gDangers</td>\n",
       "      <td>1</td>\n",
       "      <td>What us look real climate science known long t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@AlternMedicine1</td>\n",
       "      <td>1</td>\n",
       "      <td>Colombian Insurance Providers Required To Cove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>@AmyMainzer</td>\n",
       "      <td>0</td>\n",
       "      <td>Appreciated chance speak need science-based go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>@Anastas32451695</td>\n",
       "      <td>1</td>\n",
       "      <td>_Hof I’ll look 👀 🙏😌 _trois A Rasta fur ian.. 🇯...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>@AncestralApoth</td>\n",
       "      <td>1</td>\n",
       "      <td>Help us flood White House call line demands Bi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>@AnnleeElisha</td>\n",
       "      <td>1</td>\n",
       "      <td>GRAVITY???STRONG ENOUGH TO KEEP AN AIRPLANE AL...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>@Atul_Gawande</td>\n",
       "      <td>0</td>\n",
       "      <td>It may unfashionable say--and I know much work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>@BadAstronomer</td>\n",
       "      <td>0</td>\n",
       "      <td>Wait. They propagate different speeds, right? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>@CAchemtrails</td>\n",
       "      <td>1</td>\n",
       "      <td>chemtrails ☠️      chemtrails    chemtrails ☠...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>@CHEMTRAILSMN</td>\n",
       "      <td>1</td>\n",
       "      <td>RIP Bob Saget BobSaget BobSagetDead BobSagetDi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>@CaliVaxChoice</td>\n",
       "      <td>1</td>\n",
       "      <td>CMS Shot Mandate Does Not Alter Medical Religi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>@Canoe_Glider</td>\n",
       "      <td>1</td>\n",
       "      <td>today's stats : 5 new unfollowers, 17 non-foll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>@ChemtrailsNews</td>\n",
       "      <td>1</td>\n",
       "      <td>U​.​S. Fish Wildlife Service: For Felicia- le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>@Chemtrails_UK</td>\n",
       "      <td>1</td>\n",
       "      <td>LIVE: New round protests COVID-19 lockdown mea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>@DSL1912</td>\n",
       "      <td>1</td>\n",
       "      <td>So coworker double jabbed got sick, got tested...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>@DanTGilbert</td>\n",
       "      <td>0</td>\n",
       "      <td>You’ve missed important work. _Thaler STUMBLIN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>@DinosaurEarth</td>\n",
       "      <td>1</td>\n",
       "      <td>That's government wants think Dinosaurs planet...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>@DrButtar</td>\n",
       "      <td>1</td>\n",
       "      <td>Want know push agenda children getting vac’d? ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>@DrChrisNorthrup</td>\n",
       "      <td>1</td>\n",
       "      <td>Amy Loftus I great conversation menopause men....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>@DrVes</td>\n",
       "      <td>0</td>\n",
       "      <td>_Shaw My favorites among top 50 , really depen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>@EMFRebel</td>\n",
       "      <td>1</td>\n",
       "      <td>\"That kill us makes us stronger.\" - Nietzsche ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>@EndTheGlobe</td>\n",
       "      <td>1</td>\n",
       "      <td>_theone Make sure post original Tweet enter co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>@EricTopol</td>\n",
       "      <td>0</td>\n",
       "      <td>Comparison prior Alpha Delta waves outcomes Is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>@FlatArthur</td>\n",
       "      <td>1</td>\n",
       "      <td>I relate. _n There posts regarding 2nd! Her da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>@FlatAwakening</td>\n",
       "      <td>1</td>\n",
       "      <td>Omg I never think that??? Whats biggest proof ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>@FlatEarthBaba</td>\n",
       "      <td>1</td>\n",
       "      <td>Ok see irony here? Circumnavigation या नौपरिसं...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>@FlatEarthCity</td>\n",
       "      <td>1</td>\n",
       "      <td>oh didnt see \"charity\" sports werk did? firmam...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>@FlatEarthEffect</td>\n",
       "      <td>1</td>\n",
       "      <td>Hey OkGoForMoreFun(), thank following Hey terr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>@FlatEarthOrg</td>\n",
       "      <td>1</td>\n",
       "      <td>Hi Mike! The incompetent insults unnecessary -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>@FlatEarthTshirt</td>\n",
       "      <td>1</td>\n",
       "      <td>NewProfilePic 🐧4000 Flat Earth Conspiracy Pen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>@FlatRealm</td>\n",
       "      <td>1</td>\n",
       "      <td>Just 1 unfollower today found tracked 3 people...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>@FlatSmacker</td>\n",
       "      <td>1</td>\n",
       "      <td>_jo Research successes non-vaxed. I lots famil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>@GMOFreeUSA</td>\n",
       "      <td>1</td>\n",
       "      <td>Every single rainfall runoff drainage basin ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>@GlobalCHEMTRAIL</td>\n",
       "      <td>1</td>\n",
       "      <td>Sunny chance Chemtrails Airplane pollution cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>@Gylauer</td>\n",
       "      <td>1</td>\n",
       "      <td>Somos exemplos conseguiu baixa pcr de minha m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>@HansRosling</td>\n",
       "      <td>0</td>\n",
       "      <td>Thanks everyone help keeping Hans’ vision aliv...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>@HegKong</td>\n",
       "      <td>1</td>\n",
       "      <td>Psychologists cardiologists delighted.  Anybod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>@HighWireTalk</td>\n",
       "      <td>1</td>\n",
       "      <td>NovakDjokovic “I would like wish players, tour...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>@JCVenter</td>\n",
       "      <td>0</td>\n",
       "      <td>Darwin likes martini olives This one great med...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>@JakeMaverick5</td>\n",
       "      <td>1</td>\n",
       "      <td>And mainstream media, Telegraph, seemingly try...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>@JasminMartino</td>\n",
       "      <td>1</td>\n",
       "      <td>go vacation! beach mountain? Beautiful New Yor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>@JohnAllenPaulos</td>\n",
       "      <td>0</td>\n",
       "      <td>Amos Tversky Daniel Kahneman, described and/or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>@JustWakeUp8</td>\n",
       "      <td>1</td>\n",
       "      <td>Fake be!! Demonic Jeff bezos suing nasa fake \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>@KenzoAmariyo</td>\n",
       "      <td>1</td>\n",
       "      <td>So true, true. Perhaps year closes look back a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>@KimShute_NY</td>\n",
       "      <td>1</td>\n",
       "      <td>Best Wishes You All Happy New Year filled Heal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>@Knowfree77</td>\n",
       "      <td>1</td>\n",
       "      <td>j No No No you’re wrong side history pandemic ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>@LKrauss1</td>\n",
       "      <td>0</td>\n",
       "      <td>He’d like think so. Dog undaunted. Was happy l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>@LabSpaces</td>\n",
       "      <td>0</td>\n",
       "      <td>Oooh, pretty spiffy informatics positions open...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>@LaurenceBacchus</td>\n",
       "      <td>1</td>\n",
       "      <td>The media marketing arm pharma. RIP Bob Saget....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>@LookTheFuckUp_</td>\n",
       "      <td>1</td>\n",
       "      <td>It’s humidity 🤤 An assault sky afternoon. Seri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>@Lumineuse72</td>\n",
       "      <td>1</td>\n",
       "      <td>How many d0ze$ require realize n0t health...hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>@MakimuraYusaku</td>\n",
       "      <td>1</td>\n",
       "      <td>森保… 間違いなく、学校の教室や幼保の保護者の間での軋轢を生む。愚策。 親の年収による分断。...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>@MarcusduSautoy</td>\n",
       "      <td>0</td>\n",
       "      <td>_b12345 How frustrating. anything help publish...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>@MargoCatholic</td>\n",
       "      <td>1</td>\n",
       "      <td>_Elf Ricotta delicious! And i’m super picky ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>@MedicineAlt</td>\n",
       "      <td>1</td>\n",
       "      <td>Advantages Using An Ear Thermometer - EarTherm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>@MichaelEMann</td>\n",
       "      <td>0</td>\n",
       "      <td>Thanks. Yes, published couple decades ago! 🙂 @...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>@MyLindseyMcKeon</td>\n",
       "      <td>1</td>\n",
       "      <td>💗🔥🙌🏼 Oracle | A Foundational Course via shaman...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>@NickHudsonCT</td>\n",
       "      <td>1</td>\n",
       "      <td>Wah! Thread! 😂😂 Germans following rule basis s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>@Novaccineforce</td>\n",
       "      <td>1</td>\n",
       "      <td>Tragic: 14-Year-Old Israeli American Girl Suff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>@OliverSacks</td>\n",
       "      <td>0</td>\n",
       "      <td>Instagram user isabellecvr commissioned beauti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>@OpChemtrails</td>\n",
       "      <td>1</td>\n",
       "      <td>Thanks still tagging us &amp;lt;3 via rsqk9s OpChe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>@OrganicConsumer</td>\n",
       "      <td>1</td>\n",
       "      <td>\"Two world’s ubiquitous important crops 7,000-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>@PdxTreehouse</td>\n",
       "      <td>1</td>\n",
       "      <td>Happy Wild Card Wednesday! REC: 91 Larry, Oran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>@ProfBrianCox</td>\n",
       "      <td>0</td>\n",
       "      <td>:-) \"The highest grossing movie birth year 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>@ProfRWinston</td>\n",
       "      <td>0</td>\n",
       "      <td>_Landy Deeply regret social distancing. Did En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>@QMFlatEarth</td>\n",
       "      <td>1</td>\n",
       "      <td>🧐🧐🧐 We look forward welcoming 🤲 Yeah, 'Austral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>@RandomSpaceFact</td>\n",
       "      <td>0</td>\n",
       "      <td>Thanks sharing!! This evening: super bright Ve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>@RebeccaSkloot</td>\n",
       "      <td>0</td>\n",
       "      <td>Thanks. It wonderful news raise enough funds r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>@RichardDawkins</td>\n",
       "      <td>0</td>\n",
       "      <td>Still reading Ian Kershaw’s biography Hitler h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>@RichardWiseman</td>\n",
       "      <td>0</td>\n",
       "      <td>Huge congrats well deserved Roger !!! Delighte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>@RobertKennedyJr</td>\n",
       "      <td>1</td>\n",
       "      <td>Wonder cost-effective successful therapeutics ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>@STOP5G_STOP5G</td>\n",
       "      <td>1</td>\n",
       "      <td>Macht endlich die Grenzen zu! Übergriffe Maila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>@SamHarrisOrg</td>\n",
       "      <td>0</td>\n",
       "      <td>Admittedly, perfect analogy. High cholesterol ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>@SebastianThrun</td>\n",
       "      <td>0</td>\n",
       "      <td>Super excited. amazing start. Congratulations....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>@SethShostak</td>\n",
       "      <td>0</td>\n",
       "      <td>Omicron ubiquitous. It's \"Attack Mutants\" talk...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>@Spacehehehe</td>\n",
       "      <td>1</td>\n",
       "      <td>The wiseman doesn’t give right answers, poses ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>@Stop5G</td>\n",
       "      <td>1</td>\n",
       "      <td>Alternatieve Media Netwerk NL-Be Het Collectie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>@SydneyChemtrail</td>\n",
       "      <td>1</td>\n",
       "      <td>The latest Daily Chemtrail Expose! Thanks _Wee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>@TheFlatEartherr</td>\n",
       "      <td>1</td>\n",
       "      <td>More gold. _Blackett A UK \"Logan Act\" badly ne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>@US4MF</td>\n",
       "      <td>1</td>\n",
       "      <td>😅🤣🤣🤣 We need build FREEDOM HOSPITALS. FUNDED B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>@VAware1986</td>\n",
       "      <td>1</td>\n",
       "      <td>I saw 6ish year old daycare horrible dermatiti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>@VaccineEdLeague</td>\n",
       "      <td>1</td>\n",
       "      <td>SIDS 1 fear. I couldn’t sleep nights till past...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>@VaccineResist</td>\n",
       "      <td>1</td>\n",
       "      <td>This young woman represents heartbeat freedom....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>@VitalityOnline</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes. Dr. Prasad absolutely correct. And Dr. Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>@Vomit911</td>\n",
       "      <td>1</td>\n",
       "      <td>__Nicole It hits $30 $100 2022 Y'all missed cl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>@WorldwideHealth</td>\n",
       "      <td>1</td>\n",
       "      <td>We think awesome track flu shot please please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>@YouthAgainst5G</td>\n",
       "      <td>1</td>\n",
       "      <td>QR code check systems great data collection...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>@_CSHD</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm going Kacey Johansing Teragram Ballroom Lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>@bengoldacre</td>\n",
       "      <td>0</td>\n",
       "      <td>Was I watching A Matter Of Life And Death las...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>@bgreene</td>\n",
       "      <td>0</td>\n",
       "      <td>Join 3 PM EST live conversation The Future Cos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>@carolynporco</td>\n",
       "      <td>0</td>\n",
       "      <td>I even read yet -- except opening -- already I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>@circleofmamas</td>\n",
       "      <td>1</td>\n",
       "      <td>Why everyone afraid open debate? There medical...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>@danariely</td>\n",
       "      <td>0</td>\n",
       "      <td>Ask Ariely: On Anticipating Allies Perceiving ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>@danlevitin</td>\n",
       "      <td>0</td>\n",
       "      <td>Trekkies—My dear friend David Livingston (dire...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>@deborahblum</td>\n",
       "      <td>0</td>\n",
       "      <td>It pleasure part India Science Festival today,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>@delbigtree</td>\n",
       "      <td>1</td>\n",
       "      <td>Trust science. IF YOU MISS THIS EVENT like tel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>@dgmacarthur</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes, would certainly unfortunate everyone link...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>@dmarble</td>\n",
       "      <td>1</td>\n",
       "      <td>Are filming soon? Loved movie Love all, daught...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>@drsimonegold</td>\n",
       "      <td>1</td>\n",
       "      <td>SCOTUS suggests healthcare workers qualified m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>@earthisaplane7</td>\n",
       "      <td>1</td>\n",
       "      <td>mckenna vr     Does earth ceiling? questioneve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>@edyong209</td>\n",
       "      <td>0</td>\n",
       "      <td>nope. Paper nice color pics don’t need them. !...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>@ehs_symptoms</td>\n",
       "      <td>1</td>\n",
       "      <td>headaches X-ray scans wireless ELSE joint pain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>@facebones777</td>\n",
       "      <td>1</td>\n",
       "      <td>How sleep? SaveRedDeadOnline If could send IL ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>@flat_earth_dude</td>\n",
       "      <td>1</td>\n",
       "      <td>Hat glaube ich gestern medienwirksame Bilder g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>@flat_its</td>\n",
       "      <td>1</td>\n",
       "      <td>Not return, never went Have u got app . If ......</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>@flatearthaddict</td>\n",
       "      <td>1</td>\n",
       "      <td>Pilots hiding VaccineSideEffects fear losing j...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>@flatearthohio</td>\n",
       "      <td>1</td>\n",
       "      <td>😅😅😅 ♥️♥️♥️ It's Toasted! 😅 Ephesians 6:12: For...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>@forcedanarchy</td>\n",
       "      <td>1</td>\n",
       "      <td>Also, What elderly/others thrown away like gar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>@forrestmaready</td>\n",
       "      <td>1</td>\n",
       "      <td>Psyence. Psyentist. Psyentific. This changed. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>@heru41</td>\n",
       "      <td>1</td>\n",
       "      <td>People recognize..the Establishment uses (Fear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>@hhnews</td>\n",
       "      <td>1</td>\n",
       "      <td>The latest Holistic Health News! Thanks holist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>@hidenhand1</td>\n",
       "      <td>1</td>\n",
       "      <td>Etsy shop etsy instagram Thanks Dan-Cristian P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>@itsBentooLong</td>\n",
       "      <td>1</td>\n",
       "      <td>Trump told people peaceful multiple times... I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>@jrickerthall</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes- basically use everything recipe 😉 Histori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>@keepit1002018</td>\n",
       "      <td>1</td>\n",
       "      <td>Jesus!! 😵 Merry Christmas everyone still stand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>@kejames</td>\n",
       "      <td>0</td>\n",
       "      <td>Why yes, yes I pretty pleased myself. Wordle21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>@kellybroganmd</td>\n",
       "      <td>1</td>\n",
       "      <td>Just posted photo Meet Jamie, Vital Life Proje...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>@kevdjenkins1</td>\n",
       "      <td>1</td>\n",
       "      <td>‘The Supreme Court Dodged Central Matter’: R.F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>@kinggary</td>\n",
       "      <td>0</td>\n",
       "      <td>Thanks , congrats crew Only would choose revis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>@laurencette</td>\n",
       "      <td>1</td>\n",
       "      <td>With Log4j vulnerability extremely widespread,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>@lifebiomedguru</td>\n",
       "      <td>1</td>\n",
       "      <td>I'm canceling stop @ Salem New England Vacatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>@mbeisen</td>\n",
       "      <td>0</td>\n",
       "      <td>First 2 guesses biologist  Wordle 211 3/6 ⬛🟨🟨⬛...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>@mercola</td>\n",
       "      <td>1</td>\n",
       "      <td>Thank support, proceeds donated nonprofit part...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>@michiokaku</td>\n",
       "      <td>0</td>\n",
       "      <td>Joint today, 1 3pm, debate/discussion Theory E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>@natural4healing</td>\n",
       "      <td>1</td>\n",
       "      <td>Eternal life sounds good I don’t come back If ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>@naturalhealthbl</td>\n",
       "      <td>1</td>\n",
       "      <td>Love Life Supplements Primal One Whey Salted C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>@neiltyson</td>\n",
       "      <td>0</td>\n",
       "      <td>At night, I occasionally dream briefly unplugg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>@neuroconscience</td>\n",
       "      <td>0</td>\n",
       "      <td>_marinazzo sources even arguments/phrasings se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>@nickworldclass</td>\n",
       "      <td>1</td>\n",
       "      <td>I posted \"Who wants learn Hclinics offer?\" Red...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>@nocompulsoryvac</td>\n",
       "      <td>1</td>\n",
       "      <td>_Bimbo You well-named. I proud one guest speak...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>@octoberxswimmer</td>\n",
       "      <td>1</td>\n",
       "      <td>I celebrated 10 year anniversary boy I met bir...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>@onthechemtrail</td>\n",
       "      <td>1</td>\n",
       "      <td>Twenty-seven years ago... “kill television” Fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>@orbitingfrog</td>\n",
       "      <td>0</td>\n",
       "      <td>The Pacman Nebula Just posted photo Day 23: Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>@paulbloomatyale</td>\n",
       "      <td>0</td>\n",
       "      <td>thank you! New forthcoming chapter w/ brillian...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>@phylogenomics</td>\n",
       "      <td>0</td>\n",
       "      <td>_moss You wise And last series - red tailed ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>@plutokiller</td>\n",
       "      <td>0</td>\n",
       "      <td>_wold Yeah sadly taken mood _of_Ultra I know b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>@proventreatment</td>\n",
       "      <td>1</td>\n",
       "      <td>Carcavol found oregano essential oil potent fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>@pzmyers</td>\n",
       "      <td>0</td>\n",
       "      <td>Tried dry run classroom tech today. How else I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>@radiation_uk</td>\n",
       "      <td>1</td>\n",
       "      <td>_1 They recite bland WHO PHE mantras based sci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>@radzzzzster</td>\n",
       "      <td>1</td>\n",
       "      <td>Distinguished lady I get stomped night multipl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>@richaelfaithful</td>\n",
       "      <td>1</td>\n",
       "      <td>First episode Tonic: A Healing Advice Podcast ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>@ritamollerpalma</td>\n",
       "      <td>1</td>\n",
       "      <td>Sign Toby Rodger’s substack…you’ll get avalanc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>@riteaid</td>\n",
       "      <td>1</td>\n",
       "      <td>We're sorry hear able get booster, Mel. Can pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>@sapinker</td>\n",
       "      <td>0</td>\n",
       "      <td>A majority Americans political persuasions sup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>@sayerjigmi</td>\n",
       "      <td>1</td>\n",
       "      <td>Dr. Fauci Megadoses Vitamin C, Ivermectin vs. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>@sbaroncohen</td>\n",
       "      <td>0</td>\n",
       "      <td>Preliminary research Casanova et al. (2020) fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>@seanmcarroll</td>\n",
       "      <td>0</td>\n",
       "      <td>Station Eleven uses clever storytelling techni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>@social_brains</td>\n",
       "      <td>0</td>\n",
       "      <td>Say anything - get 6 guesses Rich Petty, Dan G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>@starstryder</td>\n",
       "      <td>0</td>\n",
       "      <td>The cloak altered cape estate sale. I tend go ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>@timberners_lee</td>\n",
       "      <td>0</td>\n",
       "      <td>To preserve open, global internet sparks innov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>@truthvaxwarrior</td>\n",
       "      <td>1</td>\n",
       "      <td>Tucker Carlson vaccineinjuries COVIDVaccines H...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>@unhealthytruth</td>\n",
       "      <td>1</td>\n",
       "      <td>I can’t believe attitude Instagram calling wom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>@vaughanbell</td>\n",
       "      <td>0</td>\n",
       "      <td>Really exciting study Good piece current state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>@vaxxed2</td>\n",
       "      <td>1</td>\n",
       "      <td>Make sure go website sign email list join tele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>@wanderinganimal</td>\n",
       "      <td>1</td>\n",
       "      <td>_ 1 But read tweets talking unresearched Georg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>@wddty</td>\n",
       "      <td>1</td>\n",
       "      <td>Air pollution could big factor influences seve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>@yattypat</td>\n",
       "      <td>1</td>\n",
       "      <td>_says _ukulele And suicides? Fatal car acciden...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>TNaturalHealing</td>\n",
       "      <td>1</td>\n",
       "      <td>_sarig You guys better crush earnings Nov 8th ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              account  class  \\\n",
       "0        @2020science      0   \n",
       "1     @5GAwarenessNow      1   \n",
       "2        @5gAwareness      1   \n",
       "3          @5gDangers      1   \n",
       "4    @AlternMedicine1      1   \n",
       "5         @AmyMainzer      0   \n",
       "6    @Anastas32451695      1   \n",
       "7     @AncestralApoth      1   \n",
       "8       @AnnleeElisha      1   \n",
       "9       @Atul_Gawande      0   \n",
       "10     @BadAstronomer      0   \n",
       "11      @CAchemtrails      1   \n",
       "12      @CHEMTRAILSMN      1   \n",
       "13     @CaliVaxChoice      1   \n",
       "14      @Canoe_Glider      1   \n",
       "15    @ChemtrailsNews      1   \n",
       "16     @Chemtrails_UK      1   \n",
       "17           @DSL1912      1   \n",
       "18       @DanTGilbert      0   \n",
       "19     @DinosaurEarth      1   \n",
       "20          @DrButtar      1   \n",
       "21   @DrChrisNorthrup      1   \n",
       "22             @DrVes      0   \n",
       "23          @EMFRebel      1   \n",
       "24       @EndTheGlobe      1   \n",
       "25         @EricTopol      0   \n",
       "26        @FlatArthur      1   \n",
       "27     @FlatAwakening      1   \n",
       "28     @FlatEarthBaba      1   \n",
       "29     @FlatEarthCity      1   \n",
       "30   @FlatEarthEffect      1   \n",
       "31      @FlatEarthOrg      1   \n",
       "32   @FlatEarthTshirt      1   \n",
       "33         @FlatRealm      1   \n",
       "34       @FlatSmacker      1   \n",
       "35        @GMOFreeUSA      1   \n",
       "36   @GlobalCHEMTRAIL      1   \n",
       "37           @Gylauer      1   \n",
       "38       @HansRosling      0   \n",
       "39           @HegKong      1   \n",
       "40      @HighWireTalk      1   \n",
       "41          @JCVenter      0   \n",
       "42     @JakeMaverick5      1   \n",
       "43     @JasminMartino      1   \n",
       "44   @JohnAllenPaulos      0   \n",
       "45       @JustWakeUp8      1   \n",
       "46      @KenzoAmariyo      1   \n",
       "47       @KimShute_NY      1   \n",
       "48        @Knowfree77      1   \n",
       "49          @LKrauss1      0   \n",
       "50         @LabSpaces      0   \n",
       "51   @LaurenceBacchus      1   \n",
       "52    @LookTheFuckUp_      1   \n",
       "53       @Lumineuse72      1   \n",
       "54    @MakimuraYusaku      1   \n",
       "55    @MarcusduSautoy      0   \n",
       "56     @MargoCatholic      1   \n",
       "57       @MedicineAlt      1   \n",
       "58      @MichaelEMann      0   \n",
       "59   @MyLindseyMcKeon      1   \n",
       "60      @NickHudsonCT      1   \n",
       "61    @Novaccineforce      1   \n",
       "62       @OliverSacks      0   \n",
       "63      @OpChemtrails      1   \n",
       "64   @OrganicConsumer      1   \n",
       "65      @PdxTreehouse      1   \n",
       "66      @ProfBrianCox      0   \n",
       "67      @ProfRWinston      0   \n",
       "68       @QMFlatEarth      1   \n",
       "69   @RandomSpaceFact      0   \n",
       "70     @RebeccaSkloot      0   \n",
       "71    @RichardDawkins      0   \n",
       "72    @RichardWiseman      0   \n",
       "73   @RobertKennedyJr      1   \n",
       "74     @STOP5G_STOP5G      1   \n",
       "75      @SamHarrisOrg      0   \n",
       "76    @SebastianThrun      0   \n",
       "77       @SethShostak      0   \n",
       "78       @Spacehehehe      1   \n",
       "79            @Stop5G      1   \n",
       "80   @SydneyChemtrail      1   \n",
       "81   @TheFlatEartherr      1   \n",
       "82             @US4MF      1   \n",
       "83        @VAware1986      1   \n",
       "84   @VaccineEdLeague      1   \n",
       "85     @VaccineResist      1   \n",
       "86    @VitalityOnline      1   \n",
       "87          @Vomit911      1   \n",
       "88   @WorldwideHealth      1   \n",
       "89    @YouthAgainst5G      1   \n",
       "90             @_CSHD      1   \n",
       "91       @bengoldacre      0   \n",
       "92           @bgreene      0   \n",
       "93      @carolynporco      0   \n",
       "94     @circleofmamas      1   \n",
       "95         @danariely      0   \n",
       "96        @danlevitin      0   \n",
       "97       @deborahblum      0   \n",
       "98        @delbigtree      1   \n",
       "99       @dgmacarthur      0   \n",
       "100          @dmarble      1   \n",
       "101     @drsimonegold      1   \n",
       "102   @earthisaplane7      1   \n",
       "103        @edyong209      0   \n",
       "104     @ehs_symptoms      1   \n",
       "105     @facebones777      1   \n",
       "106  @flat_earth_dude      1   \n",
       "107         @flat_its      1   \n",
       "108  @flatearthaddict      1   \n",
       "109    @flatearthohio      1   \n",
       "110    @forcedanarchy      1   \n",
       "111   @forrestmaready      1   \n",
       "112           @heru41      1   \n",
       "113           @hhnews      1   \n",
       "114       @hidenhand1      1   \n",
       "115    @itsBentooLong      1   \n",
       "116     @jrickerthall      1   \n",
       "117    @keepit1002018      1   \n",
       "118          @kejames      0   \n",
       "119    @kellybroganmd      1   \n",
       "120     @kevdjenkins1      1   \n",
       "121         @kinggary      0   \n",
       "122      @laurencette      1   \n",
       "123   @lifebiomedguru      1   \n",
       "124          @mbeisen      0   \n",
       "125          @mercola      1   \n",
       "126       @michiokaku      0   \n",
       "127  @natural4healing      1   \n",
       "128  @naturalhealthbl      1   \n",
       "129        @neiltyson      0   \n",
       "130  @neuroconscience      0   \n",
       "131   @nickworldclass      1   \n",
       "132  @nocompulsoryvac      1   \n",
       "133  @octoberxswimmer      1   \n",
       "134   @onthechemtrail      1   \n",
       "135     @orbitingfrog      0   \n",
       "136  @paulbloomatyale      0   \n",
       "137    @phylogenomics      0   \n",
       "138      @plutokiller      0   \n",
       "139  @proventreatment      1   \n",
       "140          @pzmyers      0   \n",
       "141     @radiation_uk      1   \n",
       "142      @radzzzzster      1   \n",
       "143  @richaelfaithful      1   \n",
       "144  @ritamollerpalma      1   \n",
       "145          @riteaid      1   \n",
       "146         @sapinker      0   \n",
       "147       @sayerjigmi      1   \n",
       "148      @sbaroncohen      0   \n",
       "149     @seanmcarroll      0   \n",
       "150    @social_brains      0   \n",
       "151      @starstryder      0   \n",
       "152   @timberners_lee      0   \n",
       "153  @truthvaxwarrior      1   \n",
       "154   @unhealthytruth      1   \n",
       "155      @vaughanbell      0   \n",
       "156          @vaxxed2      1   \n",
       "157  @wanderinganimal      1   \n",
       "158            @wddty      1   \n",
       "159         @yattypat      1   \n",
       "160   TNaturalHealing      1   \n",
       "\n",
       "                                         filtered_text  \n",
       "0    Have reached peak produce labeling?! Congrats ...  \n",
       "1    shes hot too. matter...but matters _FTW ZING! ...  \n",
       "2    Oh like masonic father locked hilary? Oops!! I...  \n",
       "3    What us look real climate science known long t...  \n",
       "4    Colombian Insurance Providers Required To Cove...  \n",
       "5    Appreciated chance speak need science-based go...  \n",
       "6    _Hof I’ll look 👀 🙏😌 _trois A Rasta fur ian.. 🇯...  \n",
       "7    Help us flood White House call line demands Bi...  \n",
       "8    GRAVITY???STRONG ENOUGH TO KEEP AN AIRPLANE AL...  \n",
       "9    It may unfashionable say--and I know much work...  \n",
       "10   Wait. They propagate different speeds, right? ...  \n",
       "11    chemtrails ☠️      chemtrails    chemtrails ☠...  \n",
       "12   RIP Bob Saget BobSaget BobSagetDead BobSagetDi...  \n",
       "13   CMS Shot Mandate Does Not Alter Medical Religi...  \n",
       "14   today's stats : 5 new unfollowers, 17 non-foll...  \n",
       "15    U​.​S. Fish Wildlife Service: For Felicia- le...  \n",
       "16   LIVE: New round protests COVID-19 lockdown mea...  \n",
       "17   So coworker double jabbed got sick, got tested...  \n",
       "18   You’ve missed important work. _Thaler STUMBLIN...  \n",
       "19   That's government wants think Dinosaurs planet...  \n",
       "20   Want know push agenda children getting vac’d? ...  \n",
       "21   Amy Loftus I great conversation menopause men....  \n",
       "22   _Shaw My favorites among top 50 , really depen...  \n",
       "23   \"That kill us makes us stronger.\" - Nietzsche ...  \n",
       "24   _theone Make sure post original Tweet enter co...  \n",
       "25   Comparison prior Alpha Delta waves outcomes Is...  \n",
       "26   I relate. _n There posts regarding 2nd! Her da...  \n",
       "27   Omg I never think that??? Whats biggest proof ...  \n",
       "28   Ok see irony here? Circumnavigation या नौपरिसं...  \n",
       "29   oh didnt see \"charity\" sports werk did? firmam...  \n",
       "30   Hey OkGoForMoreFun(), thank following Hey terr...  \n",
       "31   Hi Mike! The incompetent insults unnecessary -...  \n",
       "32    NewProfilePic 🐧4000 Flat Earth Conspiracy Pen...  \n",
       "33   Just 1 unfollower today found tracked 3 people...  \n",
       "34   _jo Research successes non-vaxed. I lots famil...  \n",
       "35   Every single rainfall runoff drainage basin ar...  \n",
       "36   Sunny chance Chemtrails Airplane pollution cre...  \n",
       "37    Somos exemplos conseguiu baixa pcr de minha m...  \n",
       "38   Thanks everyone help keeping Hans’ vision aliv...  \n",
       "39   Psychologists cardiologists delighted.  Anybod...  \n",
       "40   NovakDjokovic “I would like wish players, tour...  \n",
       "41   Darwin likes martini olives This one great med...  \n",
       "42   And mainstream media, Telegraph, seemingly try...  \n",
       "43   go vacation! beach mountain? Beautiful New Yor...  \n",
       "44   Amos Tversky Daniel Kahneman, described and/or...  \n",
       "45   Fake be!! Demonic Jeff bezos suing nasa fake \"...  \n",
       "46   So true, true. Perhaps year closes look back a...  \n",
       "47   Best Wishes You All Happy New Year filled Heal...  \n",
       "48   j No No No you’re wrong side history pandemic ...  \n",
       "49   He’d like think so. Dog undaunted. Was happy l...  \n",
       "50   Oooh, pretty spiffy informatics positions open...  \n",
       "51   The media marketing arm pharma. RIP Bob Saget....  \n",
       "52   It’s humidity 🤤 An assault sky afternoon. Seri...  \n",
       "53   How many d0ze$ require realize n0t health...hu...  \n",
       "54   森保… 間違いなく、学校の教室や幼保の保護者の間での軋轢を生む。愚策。 親の年収による分断。...  \n",
       "55   _b12345 How frustrating. anything help publish...  \n",
       "56   _Elf Ricotta delicious! And i’m super picky ch...  \n",
       "57   Advantages Using An Ear Thermometer - EarTherm...  \n",
       "58   Thanks. Yes, published couple decades ago! 🙂 @...  \n",
       "59   💗🔥🙌🏼 Oracle | A Foundational Course via shaman...  \n",
       "60   Wah! Thread! 😂😂 Germans following rule basis s...  \n",
       "61   Tragic: 14-Year-Old Israeli American Girl Suff...  \n",
       "62   Instagram user isabellecvr commissioned beauti...  \n",
       "63   Thanks still tagging us &lt;3 via rsqk9s OpChe...  \n",
       "64   \"Two world’s ubiquitous important crops 7,000-...  \n",
       "65   Happy Wild Card Wednesday! REC: 91 Larry, Oran...  \n",
       "66   :-) \"The highest grossing movie birth year 202...  \n",
       "67   _Landy Deeply regret social distancing. Did En...  \n",
       "68   🧐🧐🧐 We look forward welcoming 🤲 Yeah, 'Austral...  \n",
       "69   Thanks sharing!! This evening: super bright Ve...  \n",
       "70   Thanks. It wonderful news raise enough funds r...  \n",
       "71   Still reading Ian Kershaw’s biography Hitler h...  \n",
       "72   Huge congrats well deserved Roger !!! Delighte...  \n",
       "73   Wonder cost-effective successful therapeutics ...  \n",
       "74   Macht endlich die Grenzen zu! Übergriffe Maila...  \n",
       "75   Admittedly, perfect analogy. High cholesterol ...  \n",
       "76   Super excited. amazing start. Congratulations....  \n",
       "77   Omicron ubiquitous. It's \"Attack Mutants\" talk...  \n",
       "78   The wiseman doesn’t give right answers, poses ...  \n",
       "79   Alternatieve Media Netwerk NL-Be Het Collectie...  \n",
       "80   The latest Daily Chemtrail Expose! Thanks _Wee...  \n",
       "81   More gold. _Blackett A UK \"Logan Act\" badly ne...  \n",
       "82   😅🤣🤣🤣 We need build FREEDOM HOSPITALS. FUNDED B...  \n",
       "83   I saw 6ish year old daycare horrible dermatiti...  \n",
       "84   SIDS 1 fear. I couldn’t sleep nights till past...  \n",
       "85   This young woman represents heartbeat freedom....  \n",
       "86   Yes. Dr. Prasad absolutely correct. And Dr. Th...  \n",
       "87   __Nicole It hits $30 $100 2022 Y'all missed cl...  \n",
       "88   We think awesome track flu shot please please ...  \n",
       "89      QR code check systems great data collection...  \n",
       "90   I'm going Kacey Johansing Teragram Ballroom Lo...  \n",
       "91    Was I watching A Matter Of Life And Death las...  \n",
       "92   Join 3 PM EST live conversation The Future Cos...  \n",
       "93   I even read yet -- except opening -- already I...  \n",
       "94   Why everyone afraid open debate? There medical...  \n",
       "95   Ask Ariely: On Anticipating Allies Perceiving ...  \n",
       "96   Trekkies—My dear friend David Livingston (dire...  \n",
       "97   It pleasure part India Science Festival today,...  \n",
       "98   Trust science. IF YOU MISS THIS EVENT like tel...  \n",
       "99   Yes, would certainly unfortunate everyone link...  \n",
       "100  Are filming soon? Loved movie Love all, daught...  \n",
       "101  SCOTUS suggests healthcare workers qualified m...  \n",
       "102  mckenna vr     Does earth ceiling? questioneve...  \n",
       "103  nope. Paper nice color pics don’t need them. !...  \n",
       "104  headaches X-ray scans wireless ELSE joint pain...  \n",
       "105  How sleep? SaveRedDeadOnline If could send IL ...  \n",
       "106  Hat glaube ich gestern medienwirksame Bilder g...  \n",
       "107  Not return, never went Have u got app . If ......  \n",
       "108  Pilots hiding VaccineSideEffects fear losing j...  \n",
       "109  😅😅😅 ♥️♥️♥️ It's Toasted! 😅 Ephesians 6:12: For...  \n",
       "110  Also, What elderly/others thrown away like gar...  \n",
       "111  Psyence. Psyentist. Psyentific. This changed. ...  \n",
       "112  People recognize..the Establishment uses (Fear...  \n",
       "113  The latest Holistic Health News! Thanks holist...  \n",
       "114  Etsy shop etsy instagram Thanks Dan-Cristian P...  \n",
       "115  Trump told people peaceful multiple times... I...  \n",
       "116  Yes- basically use everything recipe 😉 Histori...  \n",
       "117  Jesus!! 😵 Merry Christmas everyone still stand...  \n",
       "118  Why yes, yes I pretty pleased myself. Wordle21...  \n",
       "119  Just posted photo Meet Jamie, Vital Life Proje...  \n",
       "120  ‘The Supreme Court Dodged Central Matter’: R.F...  \n",
       "121  Thanks , congrats crew Only would choose revis...  \n",
       "122  With Log4j vulnerability extremely widespread,...  \n",
       "123  I'm canceling stop @ Salem New England Vacatio...  \n",
       "124  First 2 guesses biologist  Wordle 211 3/6 ⬛🟨🟨⬛...  \n",
       "125  Thank support, proceeds donated nonprofit part...  \n",
       "126  Joint today, 1 3pm, debate/discussion Theory E...  \n",
       "127  Eternal life sounds good I don’t come back If ...  \n",
       "128  Love Life Supplements Primal One Whey Salted C...  \n",
       "129  At night, I occasionally dream briefly unplugg...  \n",
       "130  _marinazzo sources even arguments/phrasings se...  \n",
       "131  I posted \"Who wants learn Hclinics offer?\" Red...  \n",
       "132  _Bimbo You well-named. I proud one guest speak...  \n",
       "133  I celebrated 10 year anniversary boy I met bir...  \n",
       "134  Twenty-seven years ago... “kill television” Fr...  \n",
       "135  The Pacman Nebula Just posted photo Day 23: Th...  \n",
       "136  thank you! New forthcoming chapter w/ brillian...  \n",
       "137  _moss You wise And last series - red tailed ha...  \n",
       "138  _wold Yeah sadly taken mood _of_Ultra I know b...  \n",
       "139  Carcavol found oregano essential oil potent fo...  \n",
       "140  Tried dry run classroom tech today. How else I...  \n",
       "141  _1 They recite bland WHO PHE mantras based sci...  \n",
       "142  Distinguished lady I get stomped night multipl...  \n",
       "143  First episode Tonic: A Healing Advice Podcast ...  \n",
       "144  Sign Toby Rodger’s substack…you’ll get avalanc...  \n",
       "145  We're sorry hear able get booster, Mel. Can pl...  \n",
       "146  A majority Americans political persuasions sup...  \n",
       "147  Dr. Fauci Megadoses Vitamin C, Ivermectin vs. ...  \n",
       "148  Preliminary research Casanova et al. (2020) fo...  \n",
       "149  Station Eleven uses clever storytelling techni...  \n",
       "150  Say anything - get 6 guesses Rich Petty, Dan G...  \n",
       "151  The cloak altered cape estate sale. I tend go ...  \n",
       "152  To preserve open, global internet sparks innov...  \n",
       "153  Tucker Carlson vaccineinjuries COVIDVaccines H...  \n",
       "154  I can’t believe attitude Instagram calling wom...  \n",
       "155  Really exciting study Good piece current state...  \n",
       "156  Make sure go website sign email list join tele...  \n",
       "157  _ 1 But read tweets talking unresearched Georg...  \n",
       "158  Air pollution could big factor influences seve...  \n",
       "159  _says _ukulele And suicides? Fatal car acciden...  \n",
       "160  _sarig You guys better crush earnings Nov 8th ...  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_grouped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "52121c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df_grouped_text['filtered_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "a075992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = predict_batch(texts, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4cfad256",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_hf = predict_batch_hf(texts, tokenizer, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c5ad05d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.10254617, 0.49881205, 0.9246107 ], dtype=float32),\n",
       " array([0.8913398 , 0.5082953 , 0.08866754], dtype=float32),\n",
       " array([0.5062443 , 0.6621156 , 0.30783287], dtype=float32),\n",
       " array([0.7357953 , 0.56522065, 0.18659955], dtype=float32),\n",
       " array([0.450417  , 0.77969396, 0.2321847 ], dtype=float32),\n",
       " array([0.13525856, 0.53546816, 0.8793984 ], dtype=float32),\n",
       " array([0.10639387, 0.47303596, 0.93581635], dtype=float32),\n",
       " array([0.11960267, 0.6556464 , 0.79717916], dtype=float32),\n",
       " array([0.21489464, 0.5167548 , 0.8185754 ], dtype=float32),\n",
       " array([0.4102565, 0.6323186, 0.4496942], dtype=float32),\n",
       " array([0.39473087, 0.57593393, 0.56348085], dtype=float32),\n",
       " array([0.6304379 , 0.7015158 , 0.16219273], dtype=float32),\n",
       " array([0.49759525, 0.7384987 , 0.24972612], dtype=float32),\n",
       " array([0.66515344, 0.655881  , 0.18943617], dtype=float32),\n",
       " array([0.45463136, 0.7655745 , 0.24894434], dtype=float32),\n",
       " array([0.5208452 , 0.6586246 , 0.31241286], dtype=float32),\n",
       " array([0.7235909 , 0.6486386 , 0.14484772], dtype=float32),\n",
       " array([0.38693807, 0.6000184 , 0.5340066 ], dtype=float32),\n",
       " array([0.23006321, 0.53643125, 0.79057515], dtype=float32),\n",
       " array([0.52868116, 0.6313393 , 0.32893696], dtype=float32),\n",
       " array([0.8428712, 0.5336349, 0.115462 ], dtype=float32),\n",
       " array([0.06224823, 0.67316175, 0.8980064 ], dtype=float32),\n",
       " array([0.27191693, 0.6518429 , 0.58930707], dtype=float32),\n",
       " array([0.69612586, 0.6150731 , 0.19029222], dtype=float32),\n",
       " array([0.42052746, 0.7265029 , 0.3200842 ], dtype=float32),\n",
       " array([0.42082903, 0.6163266 , 0.45139357], dtype=float32),\n",
       " array([0.7008752 , 0.59233826, 0.2069825 ], dtype=float32),\n",
       " array([0.36961558, 0.6472124 , 0.49269676], dtype=float32),\n",
       " array([0.49413705, 0.818126  , 0.16722435], dtype=float32),\n",
       " array([0.7316194, 0.6439612, 0.1388272], dtype=float32),\n",
       " array([0.0581963 , 0.8522203 , 0.73029256], dtype=float32),\n",
       " array([0.6183068 , 0.5863208 , 0.29797193], dtype=float32),\n",
       " array([0.21883813, 0.7615249 , 0.5338508 ], dtype=float32),\n",
       " array([0.11440633, 0.7432548 , 0.72397274], dtype=float32),\n",
       " array([0.51059204, 0.5357301 , 0.4528627 ], dtype=float32),\n",
       " array([0.71005905, 0.6324552 , 0.15852326], dtype=float32),\n",
       " array([0.71348894, 0.6837957 , 0.1309496 ], dtype=float32),\n",
       " array([0.3624724 , 0.7981864 , 0.29602686], dtype=float32),\n",
       " array([0.30261248, 0.6453493 , 0.5560449 ], dtype=float32),\n",
       " array([0.49074957, 0.574472  , 0.43143725], dtype=float32),\n",
       " array([0.6606198 , 0.70897824, 0.15085624], dtype=float32),\n",
       " array([0.617825  , 0.6203547 , 0.26206037], dtype=float32),\n",
       " array([0.82540536, 0.58317375, 0.10644335], dtype=float32),\n",
       " array([0.15255708, 0.42072693, 0.93145365], dtype=float32),\n",
       " array([0.53942174, 0.6084912 , 0.34211963], dtype=float32),\n",
       " array([0.80503035, 0.55595046, 0.14090486], dtype=float32),\n",
       " array([0.14204621, 0.64046   , 0.789578  ], dtype=float32),\n",
       " array([0.12886004, 0.48632804, 0.9113835 ], dtype=float32),\n",
       " array([0.7445826 , 0.5956079 , 0.16811346], dtype=float32),\n",
       " array([0.14795943, 0.5443809 , 0.8674688 ], dtype=float32),\n",
       " array([0.53416246, 0.73360544, 0.21695203], dtype=float32),\n",
       " array([0.8142026 , 0.55504364, 0.13190849], dtype=float32),\n",
       " array([0.7615857 , 0.572873  , 0.16064987], dtype=float32),\n",
       " array([0.49629176, 0.63110304, 0.35690263], dtype=float32),\n",
       " array([0.5802967 , 0.7793869 , 0.16745229], dtype=float32),\n",
       " array([0.27307212, 0.5884387 , 0.67568576], dtype=float32),\n",
       " array([0.6593606 , 0.54091215, 0.28877544], dtype=float32),\n",
       " array([0.43042782, 0.6909177 , 0.3442566 ], dtype=float32),\n",
       " array([0.52025706, 0.66351753, 0.29756096], dtype=float32),\n",
       " array([0.28460327, 0.65046155, 0.5505132 ], dtype=float32),\n",
       " array([0.8100963 , 0.551503  , 0.13985196], dtype=float32),\n",
       " array([0.47489667, 0.64756984, 0.35451707], dtype=float32),\n",
       " array([0.17945042, 0.6932338 , 0.69443333], dtype=float32),\n",
       " array([0.20447867, 0.65289104, 0.67798716], dtype=float32),\n",
       " array([0.5711811 , 0.62696624, 0.27247712], dtype=float32),\n",
       " array([0.04083499, 0.60833573, 0.95569915], dtype=float32),\n",
       " array([0.11466732, 0.57072103, 0.8824818 ], dtype=float32),\n",
       " array([0.41511253, 0.5729611 , 0.5134236 ], dtype=float32),\n",
       " array([0.16081586, 0.6285259 , 0.76681733], dtype=float32),\n",
       " array([0.06614557, 0.6571137 , 0.9077309 ], dtype=float32),\n",
       " array([0.06888846, 0.5476124 , 0.9361922 ], dtype=float32),\n",
       " array([0.26505855, 0.5899382 , 0.6795452 ], dtype=float32),\n",
       " array([0.10756201, 0.45908386, 0.94424325], dtype=float32),\n",
       " array([0.66959476, 0.66092706, 0.17529954], dtype=float32),\n",
       " array([0.4720826 , 0.71995246, 0.27090898], dtype=float32),\n",
       " array([0.27295524, 0.5532035 , 0.720056  ], dtype=float32),\n",
       " array([0.07814687, 0.3938759 , 0.9732635 ], dtype=float32),\n",
       " array([0.5633455 , 0.6405358 , 0.28843772], dtype=float32),\n",
       " array([0.73289156, 0.63872004, 0.1502964 ], dtype=float32),\n",
       " array([0.54779446, 0.6561496 , 0.27793205], dtype=float32),\n",
       " array([0.21418695, 0.73048156, 0.55928   ], dtype=float32),\n",
       " array([0.68723506, 0.56026036, 0.23862296], dtype=float32),\n",
       " array([0.58835906, 0.5566608 , 0.3282945 ], dtype=float32),\n",
       " array([0.3610029 , 0.5721517 , 0.58504254], dtype=float32),\n",
       " array([0.7822823 , 0.5518899 , 0.14842287], dtype=float32),\n",
       " array([0.6800358 , 0.6336351 , 0.18331476], dtype=float32),\n",
       " array([0.5121769 , 0.6182847 , 0.34858724], dtype=float32),\n",
       " array([0.7188591 , 0.58445835, 0.1942243 ], dtype=float32),\n",
       " array([0.3464464, 0.6293478, 0.530481 ], dtype=float32),\n",
       " array([0.31516227, 0.65168685, 0.5327424 ], dtype=float32),\n",
       " array([0.3023424 , 0.7238987 , 0.47762313], dtype=float32),\n",
       " array([0.48170272, 0.58124185, 0.4502171 ], dtype=float32),\n",
       " array([0.15937717, 0.6818013 , 0.73459756], dtype=float32),\n",
       " array([0.49511763, 0.5780032 , 0.43109518], dtype=float32),\n",
       " array([0.6355582, 0.6275346, 0.232652 ], dtype=float32),\n",
       " array([0.494454  , 0.64930314, 0.3375669 ], dtype=float32),\n",
       " array([0.08227342, 0.68599665, 0.8503316 ], dtype=float32),\n",
       " array([0.66617733, 0.6083982 , 0.21656315], dtype=float32),\n",
       " array([0.41887882, 0.6253574 , 0.44635707], dtype=float32),\n",
       " array([0.52674776, 0.58409715, 0.37579235], dtype=float32),\n",
       " array([0.10088035, 0.26238978, 0.9848142 ], dtype=float32),\n",
       " array([0.85239494, 0.5763099 , 0.0911452 ], dtype=float32),\n",
       " array([0.6993531 , 0.6139601 , 0.19542715], dtype=float32),\n",
       " array([0.33779114, 0.5950869 , 0.60359687], dtype=float32),\n",
       " array([0.8014506 , 0.68677014, 0.08648027], dtype=float32),\n",
       " array([0.41972497, 0.5903051 , 0.5094146 ], dtype=float32),\n",
       " array([0.6997579 , 0.61006624, 0.19368725], dtype=float32),\n",
       " array([0.6477814 , 0.58649075, 0.25458327], dtype=float32),\n",
       " array([0.83975893, 0.5922877 , 0.10011375], dtype=float32),\n",
       " array([0.48787883, 0.58339876, 0.43087274], dtype=float32),\n",
       " array([0.8710655 , 0.5202493 , 0.09775682], dtype=float32),\n",
       " array([0.6122099 , 0.62965333, 0.24920195], dtype=float32),\n",
       " array([0.5269323 , 0.71711636, 0.24214031], dtype=float32),\n",
       " array([0.07715458, 0.7856174 , 0.7381343 ], dtype=float32),\n",
       " array([0.33514097, 0.6709788 , 0.4671931 ], dtype=float32),\n",
       " array([0.77891535, 0.55158544, 0.16250697], dtype=float32),\n",
       " array([0.08520687, 0.5485737 , 0.9233848 ], dtype=float32),\n",
       " array([0.8393513 , 0.50298655, 0.13609867], dtype=float32),\n",
       " array([0.3208915 , 0.55565935, 0.66829115], dtype=float32),\n",
       " array([0.18604457, 0.7339341 , 0.6129626 ], dtype=float32),\n",
       " array([0.80183434, 0.6198791 , 0.10932297], dtype=float32),\n",
       " array([0.21281174, 0.6544932 , 0.6766333 ], dtype=float32),\n",
       " array([0.48773474, 0.7288936 , 0.25740477], dtype=float32),\n",
       " array([0.5148548 , 0.65845597, 0.310629  ], dtype=float32),\n",
       " array([0.57931244, 0.60639185, 0.31769133], dtype=float32),\n",
       " array([0.33484328, 0.63772994, 0.50956994], dtype=float32),\n",
       " array([0.43832767, 0.6977429 , 0.34678274], dtype=float32),\n",
       " array([0.16857484, 0.57004213, 0.8249182 ], dtype=float32),\n",
       " array([0.29313257, 0.6670727 , 0.5430173 ], dtype=float32),\n",
       " array([0.28216946, 0.75528437, 0.44413844], dtype=float32),\n",
       " array([0.13021035, 0.543792  , 0.8832839 ], dtype=float32),\n",
       " array([0.18843119, 0.7205649 , 0.63933784], dtype=float32),\n",
       " array([0.38766107, 0.6137442 , 0.5068239 ], dtype=float32),\n",
       " array([0.29143485, 0.57984275, 0.66789556], dtype=float32),\n",
       " array([0.5706166 , 0.53055674, 0.39717764], dtype=float32),\n",
       " array([0.27768078, 0.69149077, 0.5523609 ], dtype=float32),\n",
       " array([0.22691986, 0.56264555, 0.76086354], dtype=float32),\n",
       " array([0.11308263, 0.64376366, 0.8426238 ], dtype=float32),\n",
       " array([0.20648973, 0.6087811 , 0.7512172 ], dtype=float32),\n",
       " array([0.38594368, 0.78684956, 0.2628182 ], dtype=float32),\n",
       " array([0.68417335, 0.58806217, 0.22469705], dtype=float32),\n",
       " array([0.41767642, 0.65778315, 0.39936152], dtype=float32),\n",
       " array([0.55881834, 0.6013134 , 0.3358759 ], dtype=float32),\n",
       " array([0.18664208, 0.7190791 , 0.633878  ], dtype=float32),\n",
       " array([0.54989487, 0.6472474 , 0.28849316], dtype=float32),\n",
       " array([0.44447765, 0.61516577, 0.44631788], dtype=float32),\n",
       " array([0.28120267, 0.72078407, 0.48326007], dtype=float32),\n",
       " array([0.7868702 , 0.6231246 , 0.11465608], dtype=float32),\n",
       " array([0.24145123, 0.72485334, 0.5281787 ], dtype=float32),\n",
       " array([0.20325604, 0.61934364, 0.7317214 ], dtype=float32),\n",
       " array([0.34573084, 0.5689923 , 0.61610436], dtype=float32),\n",
       " array([0.3562934 , 0.6616526 , 0.47543526], dtype=float32),\n",
       " array([0.20645636, 0.64535934, 0.66975766], dtype=float32),\n",
       " array([0.895988  , 0.46877927, 0.09928787], dtype=float32),\n",
       " array([0.47054082, 0.56797886, 0.4739588 ], dtype=float32),\n",
       " array([0.16343625, 0.61170214, 0.78711635], dtype=float32),\n",
       " array([0.24760173, 0.712632  , 0.53343827], dtype=float32),\n",
       " array([0.7503576 , 0.5995453 , 0.15490872], dtype=float32),\n",
       " array([0.6457664 , 0.62094414, 0.21995078], dtype=float32),\n",
       " array([0.7372333 , 0.5465422 , 0.20901011], dtype=float32),\n",
       " array([0.3009802 , 0.58317226, 0.654454  ], dtype=float32)]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0699a40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([r.tolist() for r in results])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75ea9c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['prediction'] = np.argmax(results_df[[0, 1, 2]].to_numpy(), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4dfcf44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['class'] = df_grouped_text['class'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e494f02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "94429f35",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>prediction</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102546</td>\n",
       "      <td>0.498812</td>\n",
       "      <td>0.924611</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891340</td>\n",
       "      <td>0.508295</td>\n",
       "      <td>0.088668</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.506244</td>\n",
       "      <td>0.662116</td>\n",
       "      <td>0.307833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.735795</td>\n",
       "      <td>0.565221</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.450417</td>\n",
       "      <td>0.779694</td>\n",
       "      <td>0.232185</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135259</td>\n",
       "      <td>0.535468</td>\n",
       "      <td>0.879398</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.106394</td>\n",
       "      <td>0.473036</td>\n",
       "      <td>0.935816</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.119603</td>\n",
       "      <td>0.655646</td>\n",
       "      <td>0.797179</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.214895</td>\n",
       "      <td>0.516755</td>\n",
       "      <td>0.818575</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.410257</td>\n",
       "      <td>0.632319</td>\n",
       "      <td>0.449694</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.394731</td>\n",
       "      <td>0.575934</td>\n",
       "      <td>0.563481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.630438</td>\n",
       "      <td>0.701516</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.497595</td>\n",
       "      <td>0.738499</td>\n",
       "      <td>0.249726</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.665153</td>\n",
       "      <td>0.655881</td>\n",
       "      <td>0.189436</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.454631</td>\n",
       "      <td>0.765575</td>\n",
       "      <td>0.248944</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.520845</td>\n",
       "      <td>0.658625</td>\n",
       "      <td>0.312413</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.723591</td>\n",
       "      <td>0.648639</td>\n",
       "      <td>0.144848</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.386938</td>\n",
       "      <td>0.600018</td>\n",
       "      <td>0.534007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.230063</td>\n",
       "      <td>0.536431</td>\n",
       "      <td>0.790575</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.528681</td>\n",
       "      <td>0.631339</td>\n",
       "      <td>0.328937</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.842871</td>\n",
       "      <td>0.533635</td>\n",
       "      <td>0.115462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.062248</td>\n",
       "      <td>0.673162</td>\n",
       "      <td>0.898006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.271917</td>\n",
       "      <td>0.651843</td>\n",
       "      <td>0.589307</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.696126</td>\n",
       "      <td>0.615073</td>\n",
       "      <td>0.190292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.420527</td>\n",
       "      <td>0.726503</td>\n",
       "      <td>0.320084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.420829</td>\n",
       "      <td>0.616327</td>\n",
       "      <td>0.451394</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.700875</td>\n",
       "      <td>0.592338</td>\n",
       "      <td>0.206982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.369616</td>\n",
       "      <td>0.647212</td>\n",
       "      <td>0.492697</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.494137</td>\n",
       "      <td>0.818126</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.731619</td>\n",
       "      <td>0.643961</td>\n",
       "      <td>0.138827</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.058196</td>\n",
       "      <td>0.852220</td>\n",
       "      <td>0.730293</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.618307</td>\n",
       "      <td>0.586321</td>\n",
       "      <td>0.297972</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.218838</td>\n",
       "      <td>0.761525</td>\n",
       "      <td>0.533851</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.114406</td>\n",
       "      <td>0.743255</td>\n",
       "      <td>0.723973</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.510592</td>\n",
       "      <td>0.535730</td>\n",
       "      <td>0.452863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.710059</td>\n",
       "      <td>0.632455</td>\n",
       "      <td>0.158523</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.713489</td>\n",
       "      <td>0.683796</td>\n",
       "      <td>0.130950</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.362472</td>\n",
       "      <td>0.798186</td>\n",
       "      <td>0.296027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.302612</td>\n",
       "      <td>0.645349</td>\n",
       "      <td>0.556045</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.490750</td>\n",
       "      <td>0.574472</td>\n",
       "      <td>0.431437</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.660620</td>\n",
       "      <td>0.708978</td>\n",
       "      <td>0.150856</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.617825</td>\n",
       "      <td>0.620355</td>\n",
       "      <td>0.262060</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.825405</td>\n",
       "      <td>0.583174</td>\n",
       "      <td>0.106443</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.152557</td>\n",
       "      <td>0.420727</td>\n",
       "      <td>0.931454</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.539422</td>\n",
       "      <td>0.608491</td>\n",
       "      <td>0.342120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.805030</td>\n",
       "      <td>0.555950</td>\n",
       "      <td>0.140905</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.142046</td>\n",
       "      <td>0.640460</td>\n",
       "      <td>0.789578</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.128860</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.911384</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.744583</td>\n",
       "      <td>0.595608</td>\n",
       "      <td>0.168113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.147959</td>\n",
       "      <td>0.544381</td>\n",
       "      <td>0.867469</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.534162</td>\n",
       "      <td>0.733605</td>\n",
       "      <td>0.216952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.814203</td>\n",
       "      <td>0.555044</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.761586</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>0.160650</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.496292</td>\n",
       "      <td>0.631103</td>\n",
       "      <td>0.356903</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.580297</td>\n",
       "      <td>0.779387</td>\n",
       "      <td>0.167452</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.273072</td>\n",
       "      <td>0.588439</td>\n",
       "      <td>0.675686</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.659361</td>\n",
       "      <td>0.540912</td>\n",
       "      <td>0.288775</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.430428</td>\n",
       "      <td>0.690918</td>\n",
       "      <td>0.344257</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.520257</td>\n",
       "      <td>0.663518</td>\n",
       "      <td>0.297561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.284603</td>\n",
       "      <td>0.650462</td>\n",
       "      <td>0.550513</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.810096</td>\n",
       "      <td>0.551503</td>\n",
       "      <td>0.139852</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.474897</td>\n",
       "      <td>0.647570</td>\n",
       "      <td>0.354517</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.179450</td>\n",
       "      <td>0.693234</td>\n",
       "      <td>0.694433</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.204479</td>\n",
       "      <td>0.652891</td>\n",
       "      <td>0.677987</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.571181</td>\n",
       "      <td>0.626966</td>\n",
       "      <td>0.272477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.040835</td>\n",
       "      <td>0.608336</td>\n",
       "      <td>0.955699</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.114667</td>\n",
       "      <td>0.570721</td>\n",
       "      <td>0.882482</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.415113</td>\n",
       "      <td>0.572961</td>\n",
       "      <td>0.513424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.160816</td>\n",
       "      <td>0.628526</td>\n",
       "      <td>0.766817</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.066146</td>\n",
       "      <td>0.657114</td>\n",
       "      <td>0.907731</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.068888</td>\n",
       "      <td>0.547612</td>\n",
       "      <td>0.936192</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.265059</td>\n",
       "      <td>0.589938</td>\n",
       "      <td>0.679545</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.107562</td>\n",
       "      <td>0.459084</td>\n",
       "      <td>0.944243</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.669595</td>\n",
       "      <td>0.660927</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.472083</td>\n",
       "      <td>0.719952</td>\n",
       "      <td>0.270909</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.272955</td>\n",
       "      <td>0.553204</td>\n",
       "      <td>0.720056</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.078147</td>\n",
       "      <td>0.393876</td>\n",
       "      <td>0.973264</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.563345</td>\n",
       "      <td>0.640536</td>\n",
       "      <td>0.288438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.732892</td>\n",
       "      <td>0.638720</td>\n",
       "      <td>0.150296</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.547794</td>\n",
       "      <td>0.656150</td>\n",
       "      <td>0.277932</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.214187</td>\n",
       "      <td>0.730482</td>\n",
       "      <td>0.559280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.687235</td>\n",
       "      <td>0.560260</td>\n",
       "      <td>0.238623</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.588359</td>\n",
       "      <td>0.556661</td>\n",
       "      <td>0.328294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.361003</td>\n",
       "      <td>0.572152</td>\n",
       "      <td>0.585043</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.782282</td>\n",
       "      <td>0.551890</td>\n",
       "      <td>0.148423</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.680036</td>\n",
       "      <td>0.633635</td>\n",
       "      <td>0.183315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.512177</td>\n",
       "      <td>0.618285</td>\n",
       "      <td>0.348587</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.718859</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>0.194224</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.346446</td>\n",
       "      <td>0.629348</td>\n",
       "      <td>0.530481</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.315162</td>\n",
       "      <td>0.651687</td>\n",
       "      <td>0.532742</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.302342</td>\n",
       "      <td>0.723899</td>\n",
       "      <td>0.477623</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.481703</td>\n",
       "      <td>0.581242</td>\n",
       "      <td>0.450217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.159377</td>\n",
       "      <td>0.681801</td>\n",
       "      <td>0.734598</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.495118</td>\n",
       "      <td>0.578003</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.627535</td>\n",
       "      <td>0.232652</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.494454</td>\n",
       "      <td>0.649303</td>\n",
       "      <td>0.337567</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.082273</td>\n",
       "      <td>0.685997</td>\n",
       "      <td>0.850332</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.666177</td>\n",
       "      <td>0.608398</td>\n",
       "      <td>0.216563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.418879</td>\n",
       "      <td>0.625357</td>\n",
       "      <td>0.446357</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.526748</td>\n",
       "      <td>0.584097</td>\n",
       "      <td>0.375792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.100880</td>\n",
       "      <td>0.262390</td>\n",
       "      <td>0.984814</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.852395</td>\n",
       "      <td>0.576310</td>\n",
       "      <td>0.091145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.699353</td>\n",
       "      <td>0.613960</td>\n",
       "      <td>0.195427</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.337791</td>\n",
       "      <td>0.595087</td>\n",
       "      <td>0.603597</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.801451</td>\n",
       "      <td>0.686770</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.419725</td>\n",
       "      <td>0.590305</td>\n",
       "      <td>0.509415</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.699758</td>\n",
       "      <td>0.610066</td>\n",
       "      <td>0.193687</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.647781</td>\n",
       "      <td>0.586491</td>\n",
       "      <td>0.254583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.839759</td>\n",
       "      <td>0.592288</td>\n",
       "      <td>0.100114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.487879</td>\n",
       "      <td>0.583399</td>\n",
       "      <td>0.430873</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.871065</td>\n",
       "      <td>0.520249</td>\n",
       "      <td>0.097757</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.612210</td>\n",
       "      <td>0.629653</td>\n",
       "      <td>0.249202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.526932</td>\n",
       "      <td>0.717116</td>\n",
       "      <td>0.242140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.077155</td>\n",
       "      <td>0.785617</td>\n",
       "      <td>0.738134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.335141</td>\n",
       "      <td>0.670979</td>\n",
       "      <td>0.467193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.778915</td>\n",
       "      <td>0.551585</td>\n",
       "      <td>0.162507</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.085207</td>\n",
       "      <td>0.548574</td>\n",
       "      <td>0.923385</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.839351</td>\n",
       "      <td>0.502987</td>\n",
       "      <td>0.136099</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.320891</td>\n",
       "      <td>0.555659</td>\n",
       "      <td>0.668291</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.186045</td>\n",
       "      <td>0.733934</td>\n",
       "      <td>0.612963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.801834</td>\n",
       "      <td>0.619879</td>\n",
       "      <td>0.109323</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.212812</td>\n",
       "      <td>0.654493</td>\n",
       "      <td>0.676633</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.487735</td>\n",
       "      <td>0.728894</td>\n",
       "      <td>0.257405</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.514855</td>\n",
       "      <td>0.658456</td>\n",
       "      <td>0.310629</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.579312</td>\n",
       "      <td>0.606392</td>\n",
       "      <td>0.317691</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.334843</td>\n",
       "      <td>0.637730</td>\n",
       "      <td>0.509570</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.438328</td>\n",
       "      <td>0.697743</td>\n",
       "      <td>0.346783</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.168575</td>\n",
       "      <td>0.570042</td>\n",
       "      <td>0.824918</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.293133</td>\n",
       "      <td>0.667073</td>\n",
       "      <td>0.543017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.282169</td>\n",
       "      <td>0.755284</td>\n",
       "      <td>0.444138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.130210</td>\n",
       "      <td>0.543792</td>\n",
       "      <td>0.883284</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.188431</td>\n",
       "      <td>0.720565</td>\n",
       "      <td>0.639338</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.387661</td>\n",
       "      <td>0.613744</td>\n",
       "      <td>0.506824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.291435</td>\n",
       "      <td>0.579843</td>\n",
       "      <td>0.667896</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.570617</td>\n",
       "      <td>0.530557</td>\n",
       "      <td>0.397178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.277681</td>\n",
       "      <td>0.691491</td>\n",
       "      <td>0.552361</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.226920</td>\n",
       "      <td>0.562646</td>\n",
       "      <td>0.760864</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.113083</td>\n",
       "      <td>0.643764</td>\n",
       "      <td>0.842624</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.206490</td>\n",
       "      <td>0.608781</td>\n",
       "      <td>0.751217</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.385944</td>\n",
       "      <td>0.786850</td>\n",
       "      <td>0.262818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.684173</td>\n",
       "      <td>0.588062</td>\n",
       "      <td>0.224697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.417676</td>\n",
       "      <td>0.657783</td>\n",
       "      <td>0.399362</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.558818</td>\n",
       "      <td>0.601313</td>\n",
       "      <td>0.335876</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.186642</td>\n",
       "      <td>0.719079</td>\n",
       "      <td>0.633878</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.549895</td>\n",
       "      <td>0.647247</td>\n",
       "      <td>0.288493</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.444478</td>\n",
       "      <td>0.615166</td>\n",
       "      <td>0.446318</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.281203</td>\n",
       "      <td>0.720784</td>\n",
       "      <td>0.483260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.786870</td>\n",
       "      <td>0.623125</td>\n",
       "      <td>0.114656</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.241451</td>\n",
       "      <td>0.724853</td>\n",
       "      <td>0.528179</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.203256</td>\n",
       "      <td>0.619344</td>\n",
       "      <td>0.731721</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.345731</td>\n",
       "      <td>0.568992</td>\n",
       "      <td>0.616104</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.356293</td>\n",
       "      <td>0.661653</td>\n",
       "      <td>0.475435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.206456</td>\n",
       "      <td>0.645359</td>\n",
       "      <td>0.669758</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.895988</td>\n",
       "      <td>0.468779</td>\n",
       "      <td>0.099288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.470541</td>\n",
       "      <td>0.567979</td>\n",
       "      <td>0.473959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.163436</td>\n",
       "      <td>0.611702</td>\n",
       "      <td>0.787116</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.247602</td>\n",
       "      <td>0.712632</td>\n",
       "      <td>0.533438</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.750358</td>\n",
       "      <td>0.599545</td>\n",
       "      <td>0.154909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.645766</td>\n",
       "      <td>0.620944</td>\n",
       "      <td>0.219951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.737233</td>\n",
       "      <td>0.546542</td>\n",
       "      <td>0.209010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.300980</td>\n",
       "      <td>0.583172</td>\n",
       "      <td>0.654454</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2  prediction  class\n",
       "0    0.102546  0.498812  0.924611           2      0\n",
       "1    0.891340  0.508295  0.088668           0      1\n",
       "2    0.506244  0.662116  0.307833           1      1\n",
       "3    0.735795  0.565221  0.186600           0      1\n",
       "4    0.450417  0.779694  0.232185           1      1\n",
       "5    0.135259  0.535468  0.879398           2      0\n",
       "6    0.106394  0.473036  0.935816           2      1\n",
       "7    0.119603  0.655646  0.797179           2      1\n",
       "8    0.214895  0.516755  0.818575           2      1\n",
       "9    0.410257  0.632319  0.449694           1      0\n",
       "10   0.394731  0.575934  0.563481           1      0\n",
       "11   0.630438  0.701516  0.162193           1      1\n",
       "12   0.497595  0.738499  0.249726           1      1\n",
       "13   0.665153  0.655881  0.189436           0      1\n",
       "14   0.454631  0.765575  0.248944           1      1\n",
       "15   0.520845  0.658625  0.312413           1      1\n",
       "16   0.723591  0.648639  0.144848           0      1\n",
       "17   0.386938  0.600018  0.534007           1      1\n",
       "18   0.230063  0.536431  0.790575           2      0\n",
       "19   0.528681  0.631339  0.328937           1      1\n",
       "20   0.842871  0.533635  0.115462           0      1\n",
       "21   0.062248  0.673162  0.898006           2      1\n",
       "22   0.271917  0.651843  0.589307           1      0\n",
       "23   0.696126  0.615073  0.190292           0      1\n",
       "24   0.420527  0.726503  0.320084           1      1\n",
       "25   0.420829  0.616327  0.451394           1      0\n",
       "26   0.700875  0.592338  0.206982           0      1\n",
       "27   0.369616  0.647212  0.492697           1      1\n",
       "28   0.494137  0.818126  0.167224           1      1\n",
       "29   0.731619  0.643961  0.138827           0      1\n",
       "30   0.058196  0.852220  0.730293           1      1\n",
       "31   0.618307  0.586321  0.297972           0      1\n",
       "32   0.218838  0.761525  0.533851           1      1\n",
       "33   0.114406  0.743255  0.723973           1      1\n",
       "34   0.510592  0.535730  0.452863           1      1\n",
       "35   0.710059  0.632455  0.158523           0      1\n",
       "36   0.713489  0.683796  0.130950           0      1\n",
       "37   0.362472  0.798186  0.296027           1      1\n",
       "38   0.302612  0.645349  0.556045           1      0\n",
       "39   0.490750  0.574472  0.431437           1      1\n",
       "40   0.660620  0.708978  0.150856           1      1\n",
       "41   0.617825  0.620355  0.262060           1      0\n",
       "42   0.825405  0.583174  0.106443           0      1\n",
       "43   0.152557  0.420727  0.931454           2      1\n",
       "44   0.539422  0.608491  0.342120           1      0\n",
       "45   0.805030  0.555950  0.140905           0      1\n",
       "46   0.142046  0.640460  0.789578           2      1\n",
       "47   0.128860  0.486328  0.911384           2      1\n",
       "48   0.744583  0.595608  0.168113           0      1\n",
       "49   0.147959  0.544381  0.867469           2      0\n",
       "50   0.534162  0.733605  0.216952           1      0\n",
       "51   0.814203  0.555044  0.131908           0      1\n",
       "52   0.761586  0.572873  0.160650           0      1\n",
       "53   0.496292  0.631103  0.356903           1      1\n",
       "54   0.580297  0.779387  0.167452           1      1\n",
       "55   0.273072  0.588439  0.675686           2      0\n",
       "56   0.659361  0.540912  0.288775           0      1\n",
       "57   0.430428  0.690918  0.344257           1      1\n",
       "58   0.520257  0.663518  0.297561           1      0\n",
       "59   0.284603  0.650462  0.550513           1      1\n",
       "60   0.810096  0.551503  0.139852           0      1\n",
       "61   0.474897  0.647570  0.354517           1      1\n",
       "62   0.179450  0.693234  0.694433           2      0\n",
       "63   0.204479  0.652891  0.677987           2      1\n",
       "64   0.571181  0.626966  0.272477           1      1\n",
       "65   0.040835  0.608336  0.955699           2      1\n",
       "66   0.114667  0.570721  0.882482           2      0\n",
       "67   0.415113  0.572961  0.513424           1      0\n",
       "68   0.160816  0.628526  0.766817           2      1\n",
       "69   0.066146  0.657114  0.907731           2      0\n",
       "70   0.068888  0.547612  0.936192           2      0\n",
       "71   0.265059  0.589938  0.679545           2      0\n",
       "72   0.107562  0.459084  0.944243           2      0\n",
       "73   0.669595  0.660927  0.175300           0      1\n",
       "74   0.472083  0.719952  0.270909           1      1\n",
       "75   0.272955  0.553204  0.720056           2      0\n",
       "76   0.078147  0.393876  0.973264           2      0\n",
       "77   0.563345  0.640536  0.288438           1      0\n",
       "78   0.732892  0.638720  0.150296           0      1\n",
       "79   0.547794  0.656150  0.277932           1      1\n",
       "80   0.214187  0.730482  0.559280           1      1\n",
       "81   0.687235  0.560260  0.238623           0      1\n",
       "82   0.588359  0.556661  0.328294           0      1\n",
       "83   0.361003  0.572152  0.585043           2      1\n",
       "84   0.782282  0.551890  0.148423           0      1\n",
       "85   0.680036  0.633635  0.183315           0      1\n",
       "86   0.512177  0.618285  0.348587           1      1\n",
       "87   0.718859  0.584458  0.194224           0      1\n",
       "88   0.346446  0.629348  0.530481           1      1\n",
       "89   0.315162  0.651687  0.532742           1      1\n",
       "90   0.302342  0.723899  0.477623           1      1\n",
       "91   0.481703  0.581242  0.450217           1      0\n",
       "92   0.159377  0.681801  0.734598           2      0\n",
       "93   0.495118  0.578003  0.431095           1      0\n",
       "94   0.635558  0.627535  0.232652           0      1\n",
       "95   0.494454  0.649303  0.337567           1      0\n",
       "96   0.082273  0.685997  0.850332           2      0\n",
       "97   0.666177  0.608398  0.216563           0      0\n",
       "98   0.418879  0.625357  0.446357           1      1\n",
       "99   0.526748  0.584097  0.375792           1      0\n",
       "100  0.100880  0.262390  0.984814           2      1\n",
       "101  0.852395  0.576310  0.091145           0      1\n",
       "102  0.699353  0.613960  0.195427           0      1\n",
       "103  0.337791  0.595087  0.603597           2      0\n",
       "104  0.801451  0.686770  0.086480           0      1\n",
       "105  0.419725  0.590305  0.509415           1      1\n",
       "106  0.699758  0.610066  0.193687           0      1\n",
       "107  0.647781  0.586491  0.254583           0      1\n",
       "108  0.839759  0.592288  0.100114           0      1\n",
       "109  0.487879  0.583399  0.430873           1      1\n",
       "110  0.871065  0.520249  0.097757           0      1\n",
       "111  0.612210  0.629653  0.249202           1      1\n",
       "112  0.526932  0.717116  0.242140           1      1\n",
       "113  0.077155  0.785617  0.738134           1      1\n",
       "114  0.335141  0.670979  0.467193           1      1\n",
       "115  0.778915  0.551585  0.162507           0      1\n",
       "116  0.085207  0.548574  0.923385           2      1\n",
       "117  0.839351  0.502987  0.136099           0      1\n",
       "118  0.320891  0.555659  0.668291           2      0\n",
       "119  0.186045  0.733934  0.612963           1      1\n",
       "120  0.801834  0.619879  0.109323           0      1\n",
       "121  0.212812  0.654493  0.676633           2      0\n",
       "122  0.487735  0.728894  0.257405           1      1\n",
       "123  0.514855  0.658456  0.310629           1      1\n",
       "124  0.579312  0.606392  0.317691           1      0\n",
       "125  0.334843  0.637730  0.509570           1      1\n",
       "126  0.438328  0.697743  0.346783           1      0\n",
       "127  0.168575  0.570042  0.824918           2      1\n",
       "128  0.293133  0.667073  0.543017           1      1\n",
       "129  0.282169  0.755284  0.444138           1      0\n",
       "130  0.130210  0.543792  0.883284           2      0\n",
       "131  0.188431  0.720565  0.639338           1      1\n",
       "132  0.387661  0.613744  0.506824           1      1\n",
       "133  0.291435  0.579843  0.667896           2      1\n",
       "134  0.570617  0.530557  0.397178           0      1\n",
       "135  0.277681  0.691491  0.552361           1      0\n",
       "136  0.226920  0.562646  0.760864           2      0\n",
       "137  0.113083  0.643764  0.842624           2      0\n",
       "138  0.206490  0.608781  0.751217           2      0\n",
       "139  0.385944  0.786850  0.262818           1      1\n",
       "140  0.684173  0.588062  0.224697           0      0\n",
       "141  0.417676  0.657783  0.399362           1      1\n",
       "142  0.558818  0.601313  0.335876           1      1\n",
       "143  0.186642  0.719079  0.633878           1      1\n",
       "144  0.549895  0.647247  0.288493           1      1\n",
       "145  0.444478  0.615166  0.446318           1      1\n",
       "146  0.281203  0.720784  0.483260           1      0\n",
       "147  0.786870  0.623125  0.114656           0      1\n",
       "148  0.241451  0.724853  0.528179           1      0\n",
       "149  0.203256  0.619344  0.731721           2      0\n",
       "150  0.345731  0.568992  0.616104           2      0\n",
       "151  0.356293  0.661653  0.475435           1      0\n",
       "152  0.206456  0.645359  0.669758           2      0\n",
       "153  0.895988  0.468779  0.099288           0      1\n",
       "154  0.470541  0.567979  0.473959           1      1\n",
       "155  0.163436  0.611702  0.787116           2      0\n",
       "156  0.247602  0.712632  0.533438           1      1\n",
       "157  0.750358  0.599545  0.154909           0      1\n",
       "158  0.645766  0.620944  0.219951           0      1\n",
       "159  0.737233  0.546542  0.209010           0      1\n",
       "160  0.300980  0.583172  0.654454           2      1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# negative - 0\n",
    "# neutral - 1 \n",
    "# positive - 2\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "d059479a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>prediction</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102546</td>\n",
       "      <td>0.498812</td>\n",
       "      <td>0.924611</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135259</td>\n",
       "      <td>0.535468</td>\n",
       "      <td>0.879398</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.230063</td>\n",
       "      <td>0.536431</td>\n",
       "      <td>0.790575</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.147959</td>\n",
       "      <td>0.544381</td>\n",
       "      <td>0.867469</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.273072</td>\n",
       "      <td>0.588439</td>\n",
       "      <td>0.675686</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.179450</td>\n",
       "      <td>0.693234</td>\n",
       "      <td>0.694433</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.114667</td>\n",
       "      <td>0.570721</td>\n",
       "      <td>0.882482</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.066146</td>\n",
       "      <td>0.657114</td>\n",
       "      <td>0.907731</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.068888</td>\n",
       "      <td>0.547612</td>\n",
       "      <td>0.936192</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.265059</td>\n",
       "      <td>0.589938</td>\n",
       "      <td>0.679545</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.107562</td>\n",
       "      <td>0.459084</td>\n",
       "      <td>0.944243</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.272955</td>\n",
       "      <td>0.553204</td>\n",
       "      <td>0.720056</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.078147</td>\n",
       "      <td>0.393876</td>\n",
       "      <td>0.973264</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.159377</td>\n",
       "      <td>0.681801</td>\n",
       "      <td>0.734598</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.082273</td>\n",
       "      <td>0.685997</td>\n",
       "      <td>0.850332</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.337791</td>\n",
       "      <td>0.595087</td>\n",
       "      <td>0.603597</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.320891</td>\n",
       "      <td>0.555659</td>\n",
       "      <td>0.668291</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.212812</td>\n",
       "      <td>0.654493</td>\n",
       "      <td>0.676633</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.130210</td>\n",
       "      <td>0.543792</td>\n",
       "      <td>0.883284</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.226920</td>\n",
       "      <td>0.562646</td>\n",
       "      <td>0.760864</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.113083</td>\n",
       "      <td>0.643764</td>\n",
       "      <td>0.842624</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.206490</td>\n",
       "      <td>0.608781</td>\n",
       "      <td>0.751217</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.203256</td>\n",
       "      <td>0.619344</td>\n",
       "      <td>0.731721</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.345731</td>\n",
       "      <td>0.568992</td>\n",
       "      <td>0.616104</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.206456</td>\n",
       "      <td>0.645359</td>\n",
       "      <td>0.669758</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.163436</td>\n",
       "      <td>0.611702</td>\n",
       "      <td>0.787116</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2  prediction  class\n",
       "0    0.102546  0.498812  0.924611           2      0\n",
       "5    0.135259  0.535468  0.879398           2      0\n",
       "18   0.230063  0.536431  0.790575           2      0\n",
       "49   0.147959  0.544381  0.867469           2      0\n",
       "55   0.273072  0.588439  0.675686           2      0\n",
       "62   0.179450  0.693234  0.694433           2      0\n",
       "66   0.114667  0.570721  0.882482           2      0\n",
       "69   0.066146  0.657114  0.907731           2      0\n",
       "70   0.068888  0.547612  0.936192           2      0\n",
       "71   0.265059  0.589938  0.679545           2      0\n",
       "72   0.107562  0.459084  0.944243           2      0\n",
       "75   0.272955  0.553204  0.720056           2      0\n",
       "76   0.078147  0.393876  0.973264           2      0\n",
       "92   0.159377  0.681801  0.734598           2      0\n",
       "96   0.082273  0.685997  0.850332           2      0\n",
       "103  0.337791  0.595087  0.603597           2      0\n",
       "118  0.320891  0.555659  0.668291           2      0\n",
       "121  0.212812  0.654493  0.676633           2      0\n",
       "130  0.130210  0.543792  0.883284           2      0\n",
       "136  0.226920  0.562646  0.760864           2      0\n",
       "137  0.113083  0.643764  0.842624           2      0\n",
       "138  0.206490  0.608781  0.751217           2      0\n",
       "149  0.203256  0.619344  0.731721           2      0\n",
       "150  0.345731  0.568992  0.616104           2      0\n",
       "152  0.206456  0.645359  0.669758           2      0\n",
       "155  0.163436  0.611702  0.787116           2      0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df['prediction']==2) & (results_df['class']==0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "ad631761",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>prediction</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891340</td>\n",
       "      <td>0.508295</td>\n",
       "      <td>0.088668</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.735795</td>\n",
       "      <td>0.565221</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.665153</td>\n",
       "      <td>0.655881</td>\n",
       "      <td>0.189436</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.723591</td>\n",
       "      <td>0.648639</td>\n",
       "      <td>0.144848</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.842871</td>\n",
       "      <td>0.533635</td>\n",
       "      <td>0.115462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.696126</td>\n",
       "      <td>0.615073</td>\n",
       "      <td>0.190292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.700875</td>\n",
       "      <td>0.592338</td>\n",
       "      <td>0.206982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.731619</td>\n",
       "      <td>0.643961</td>\n",
       "      <td>0.138827</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.618307</td>\n",
       "      <td>0.586321</td>\n",
       "      <td>0.297972</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.710059</td>\n",
       "      <td>0.632455</td>\n",
       "      <td>0.158523</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.713489</td>\n",
       "      <td>0.683796</td>\n",
       "      <td>0.130950</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.825405</td>\n",
       "      <td>0.583174</td>\n",
       "      <td>0.106443</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.805030</td>\n",
       "      <td>0.555950</td>\n",
       "      <td>0.140905</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.744583</td>\n",
       "      <td>0.595608</td>\n",
       "      <td>0.168113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.814203</td>\n",
       "      <td>0.555044</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.761586</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>0.160650</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.659361</td>\n",
       "      <td>0.540912</td>\n",
       "      <td>0.288775</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.810096</td>\n",
       "      <td>0.551503</td>\n",
       "      <td>0.139852</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.669595</td>\n",
       "      <td>0.660927</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.732892</td>\n",
       "      <td>0.638720</td>\n",
       "      <td>0.150296</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.687235</td>\n",
       "      <td>0.560260</td>\n",
       "      <td>0.238623</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.588359</td>\n",
       "      <td>0.556661</td>\n",
       "      <td>0.328294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.782282</td>\n",
       "      <td>0.551890</td>\n",
       "      <td>0.148423</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.680036</td>\n",
       "      <td>0.633635</td>\n",
       "      <td>0.183315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.718859</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>0.194224</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.627535</td>\n",
       "      <td>0.232652</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.852395</td>\n",
       "      <td>0.576310</td>\n",
       "      <td>0.091145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.699353</td>\n",
       "      <td>0.613960</td>\n",
       "      <td>0.195427</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.801451</td>\n",
       "      <td>0.686770</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.699758</td>\n",
       "      <td>0.610066</td>\n",
       "      <td>0.193687</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.647781</td>\n",
       "      <td>0.586491</td>\n",
       "      <td>0.254583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.839759</td>\n",
       "      <td>0.592288</td>\n",
       "      <td>0.100114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.871065</td>\n",
       "      <td>0.520249</td>\n",
       "      <td>0.097757</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.778915</td>\n",
       "      <td>0.551585</td>\n",
       "      <td>0.162507</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.839351</td>\n",
       "      <td>0.502987</td>\n",
       "      <td>0.136099</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.801834</td>\n",
       "      <td>0.619879</td>\n",
       "      <td>0.109323</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.570617</td>\n",
       "      <td>0.530557</td>\n",
       "      <td>0.397178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.786870</td>\n",
       "      <td>0.623125</td>\n",
       "      <td>0.114656</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.895988</td>\n",
       "      <td>0.468779</td>\n",
       "      <td>0.099288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.750358</td>\n",
       "      <td>0.599545</td>\n",
       "      <td>0.154909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.645766</td>\n",
       "      <td>0.620944</td>\n",
       "      <td>0.219951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.737233</td>\n",
       "      <td>0.546542</td>\n",
       "      <td>0.209010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2  prediction  class\n",
       "1    0.891340  0.508295  0.088668           0      1\n",
       "3    0.735795  0.565221  0.186600           0      1\n",
       "13   0.665153  0.655881  0.189436           0      1\n",
       "16   0.723591  0.648639  0.144848           0      1\n",
       "20   0.842871  0.533635  0.115462           0      1\n",
       "23   0.696126  0.615073  0.190292           0      1\n",
       "26   0.700875  0.592338  0.206982           0      1\n",
       "29   0.731619  0.643961  0.138827           0      1\n",
       "31   0.618307  0.586321  0.297972           0      1\n",
       "35   0.710059  0.632455  0.158523           0      1\n",
       "36   0.713489  0.683796  0.130950           0      1\n",
       "42   0.825405  0.583174  0.106443           0      1\n",
       "45   0.805030  0.555950  0.140905           0      1\n",
       "48   0.744583  0.595608  0.168113           0      1\n",
       "51   0.814203  0.555044  0.131908           0      1\n",
       "52   0.761586  0.572873  0.160650           0      1\n",
       "56   0.659361  0.540912  0.288775           0      1\n",
       "60   0.810096  0.551503  0.139852           0      1\n",
       "73   0.669595  0.660927  0.175300           0      1\n",
       "78   0.732892  0.638720  0.150296           0      1\n",
       "81   0.687235  0.560260  0.238623           0      1\n",
       "82   0.588359  0.556661  0.328294           0      1\n",
       "84   0.782282  0.551890  0.148423           0      1\n",
       "85   0.680036  0.633635  0.183315           0      1\n",
       "87   0.718859  0.584458  0.194224           0      1\n",
       "94   0.635558  0.627535  0.232652           0      1\n",
       "101  0.852395  0.576310  0.091145           0      1\n",
       "102  0.699353  0.613960  0.195427           0      1\n",
       "104  0.801451  0.686770  0.086480           0      1\n",
       "106  0.699758  0.610066  0.193687           0      1\n",
       "107  0.647781  0.586491  0.254583           0      1\n",
       "108  0.839759  0.592288  0.100114           0      1\n",
       "110  0.871065  0.520249  0.097757           0      1\n",
       "115  0.778915  0.551585  0.162507           0      1\n",
       "117  0.839351  0.502987  0.136099           0      1\n",
       "120  0.801834  0.619879  0.109323           0      1\n",
       "134  0.570617  0.530557  0.397178           0      1\n",
       "147  0.786870  0.623125  0.114656           0      1\n",
       "153  0.895988  0.468779  0.099288           0      1\n",
       "157  0.750358  0.599545  0.154909           0      1\n",
       "158  0.645766  0.620944  0.219951           0      1\n",
       "159  0.737233  0.546542  0.209010           0      1"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df['prediction']==0) & (results_df['class']==1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "46fe3f12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>prediction</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.102546</td>\n",
       "      <td>0.498812</td>\n",
       "      <td>0.924611</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.891340</td>\n",
       "      <td>0.508295</td>\n",
       "      <td>0.088668</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.735795</td>\n",
       "      <td>0.565221</td>\n",
       "      <td>0.186600</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.135259</td>\n",
       "      <td>0.535468</td>\n",
       "      <td>0.879398</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.665153</td>\n",
       "      <td>0.655881</td>\n",
       "      <td>0.189436</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.723591</td>\n",
       "      <td>0.648639</td>\n",
       "      <td>0.144848</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.230063</td>\n",
       "      <td>0.536431</td>\n",
       "      <td>0.790575</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.842871</td>\n",
       "      <td>0.533635</td>\n",
       "      <td>0.115462</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.696126</td>\n",
       "      <td>0.615073</td>\n",
       "      <td>0.190292</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.700875</td>\n",
       "      <td>0.592338</td>\n",
       "      <td>0.206982</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.731619</td>\n",
       "      <td>0.643961</td>\n",
       "      <td>0.138827</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.618307</td>\n",
       "      <td>0.586321</td>\n",
       "      <td>0.297972</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.710059</td>\n",
       "      <td>0.632455</td>\n",
       "      <td>0.158523</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.713489</td>\n",
       "      <td>0.683796</td>\n",
       "      <td>0.130950</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.825405</td>\n",
       "      <td>0.583174</td>\n",
       "      <td>0.106443</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.805030</td>\n",
       "      <td>0.555950</td>\n",
       "      <td>0.140905</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.744583</td>\n",
       "      <td>0.595608</td>\n",
       "      <td>0.168113</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.147959</td>\n",
       "      <td>0.544381</td>\n",
       "      <td>0.867469</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.814203</td>\n",
       "      <td>0.555044</td>\n",
       "      <td>0.131908</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.761586</td>\n",
       "      <td>0.572873</td>\n",
       "      <td>0.160650</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.273072</td>\n",
       "      <td>0.588439</td>\n",
       "      <td>0.675686</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.659361</td>\n",
       "      <td>0.540912</td>\n",
       "      <td>0.288775</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.810096</td>\n",
       "      <td>0.551503</td>\n",
       "      <td>0.139852</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.179450</td>\n",
       "      <td>0.693234</td>\n",
       "      <td>0.694433</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.114667</td>\n",
       "      <td>0.570721</td>\n",
       "      <td>0.882482</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.066146</td>\n",
       "      <td>0.657114</td>\n",
       "      <td>0.907731</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.068888</td>\n",
       "      <td>0.547612</td>\n",
       "      <td>0.936192</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.265059</td>\n",
       "      <td>0.589938</td>\n",
       "      <td>0.679545</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.107562</td>\n",
       "      <td>0.459084</td>\n",
       "      <td>0.944243</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.669595</td>\n",
       "      <td>0.660927</td>\n",
       "      <td>0.175300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.272955</td>\n",
       "      <td>0.553204</td>\n",
       "      <td>0.720056</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.078147</td>\n",
       "      <td>0.393876</td>\n",
       "      <td>0.973264</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.732892</td>\n",
       "      <td>0.638720</td>\n",
       "      <td>0.150296</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.687235</td>\n",
       "      <td>0.560260</td>\n",
       "      <td>0.238623</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.588359</td>\n",
       "      <td>0.556661</td>\n",
       "      <td>0.328294</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.782282</td>\n",
       "      <td>0.551890</td>\n",
       "      <td>0.148423</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.680036</td>\n",
       "      <td>0.633635</td>\n",
       "      <td>0.183315</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.718859</td>\n",
       "      <td>0.584458</td>\n",
       "      <td>0.194224</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.159377</td>\n",
       "      <td>0.681801</td>\n",
       "      <td>0.734598</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.635558</td>\n",
       "      <td>0.627535</td>\n",
       "      <td>0.232652</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.082273</td>\n",
       "      <td>0.685997</td>\n",
       "      <td>0.850332</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.852395</td>\n",
       "      <td>0.576310</td>\n",
       "      <td>0.091145</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.699353</td>\n",
       "      <td>0.613960</td>\n",
       "      <td>0.195427</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>0.337791</td>\n",
       "      <td>0.595087</td>\n",
       "      <td>0.603597</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.801451</td>\n",
       "      <td>0.686770</td>\n",
       "      <td>0.086480</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>0.699758</td>\n",
       "      <td>0.610066</td>\n",
       "      <td>0.193687</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0.647781</td>\n",
       "      <td>0.586491</td>\n",
       "      <td>0.254583</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>0.839759</td>\n",
       "      <td>0.592288</td>\n",
       "      <td>0.100114</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>0.871065</td>\n",
       "      <td>0.520249</td>\n",
       "      <td>0.097757</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>0.778915</td>\n",
       "      <td>0.551585</td>\n",
       "      <td>0.162507</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>0.839351</td>\n",
       "      <td>0.502987</td>\n",
       "      <td>0.136099</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>0.320891</td>\n",
       "      <td>0.555659</td>\n",
       "      <td>0.668291</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>0.801834</td>\n",
       "      <td>0.619879</td>\n",
       "      <td>0.109323</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>0.212812</td>\n",
       "      <td>0.654493</td>\n",
       "      <td>0.676633</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>0.130210</td>\n",
       "      <td>0.543792</td>\n",
       "      <td>0.883284</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.570617</td>\n",
       "      <td>0.530557</td>\n",
       "      <td>0.397178</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.226920</td>\n",
       "      <td>0.562646</td>\n",
       "      <td>0.760864</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>0.113083</td>\n",
       "      <td>0.643764</td>\n",
       "      <td>0.842624</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0.206490</td>\n",
       "      <td>0.608781</td>\n",
       "      <td>0.751217</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.786870</td>\n",
       "      <td>0.623125</td>\n",
       "      <td>0.114656</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.203256</td>\n",
       "      <td>0.619344</td>\n",
       "      <td>0.731721</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>0.345731</td>\n",
       "      <td>0.568992</td>\n",
       "      <td>0.616104</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>0.206456</td>\n",
       "      <td>0.645359</td>\n",
       "      <td>0.669758</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>0.895988</td>\n",
       "      <td>0.468779</td>\n",
       "      <td>0.099288</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>0.163436</td>\n",
       "      <td>0.611702</td>\n",
       "      <td>0.787116</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>0.750358</td>\n",
       "      <td>0.599545</td>\n",
       "      <td>0.154909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>0.645766</td>\n",
       "      <td>0.620944</td>\n",
       "      <td>0.219951</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>0.737233</td>\n",
       "      <td>0.546542</td>\n",
       "      <td>0.209010</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2  prediction  class\n",
       "0    0.102546  0.498812  0.924611           2      0\n",
       "1    0.891340  0.508295  0.088668           0      1\n",
       "3    0.735795  0.565221  0.186600           0      1\n",
       "5    0.135259  0.535468  0.879398           2      0\n",
       "13   0.665153  0.655881  0.189436           0      1\n",
       "16   0.723591  0.648639  0.144848           0      1\n",
       "18   0.230063  0.536431  0.790575           2      0\n",
       "20   0.842871  0.533635  0.115462           0      1\n",
       "23   0.696126  0.615073  0.190292           0      1\n",
       "26   0.700875  0.592338  0.206982           0      1\n",
       "29   0.731619  0.643961  0.138827           0      1\n",
       "31   0.618307  0.586321  0.297972           0      1\n",
       "35   0.710059  0.632455  0.158523           0      1\n",
       "36   0.713489  0.683796  0.130950           0      1\n",
       "42   0.825405  0.583174  0.106443           0      1\n",
       "45   0.805030  0.555950  0.140905           0      1\n",
       "48   0.744583  0.595608  0.168113           0      1\n",
       "49   0.147959  0.544381  0.867469           2      0\n",
       "51   0.814203  0.555044  0.131908           0      1\n",
       "52   0.761586  0.572873  0.160650           0      1\n",
       "55   0.273072  0.588439  0.675686           2      0\n",
       "56   0.659361  0.540912  0.288775           0      1\n",
       "60   0.810096  0.551503  0.139852           0      1\n",
       "62   0.179450  0.693234  0.694433           2      0\n",
       "66   0.114667  0.570721  0.882482           2      0\n",
       "69   0.066146  0.657114  0.907731           2      0\n",
       "70   0.068888  0.547612  0.936192           2      0\n",
       "71   0.265059  0.589938  0.679545           2      0\n",
       "72   0.107562  0.459084  0.944243           2      0\n",
       "73   0.669595  0.660927  0.175300           0      1\n",
       "75   0.272955  0.553204  0.720056           2      0\n",
       "76   0.078147  0.393876  0.973264           2      0\n",
       "78   0.732892  0.638720  0.150296           0      1\n",
       "81   0.687235  0.560260  0.238623           0      1\n",
       "82   0.588359  0.556661  0.328294           0      1\n",
       "84   0.782282  0.551890  0.148423           0      1\n",
       "85   0.680036  0.633635  0.183315           0      1\n",
       "87   0.718859  0.584458  0.194224           0      1\n",
       "92   0.159377  0.681801  0.734598           2      0\n",
       "94   0.635558  0.627535  0.232652           0      1\n",
       "96   0.082273  0.685997  0.850332           2      0\n",
       "101  0.852395  0.576310  0.091145           0      1\n",
       "102  0.699353  0.613960  0.195427           0      1\n",
       "103  0.337791  0.595087  0.603597           2      0\n",
       "104  0.801451  0.686770  0.086480           0      1\n",
       "106  0.699758  0.610066  0.193687           0      1\n",
       "107  0.647781  0.586491  0.254583           0      1\n",
       "108  0.839759  0.592288  0.100114           0      1\n",
       "110  0.871065  0.520249  0.097757           0      1\n",
       "115  0.778915  0.551585  0.162507           0      1\n",
       "117  0.839351  0.502987  0.136099           0      1\n",
       "118  0.320891  0.555659  0.668291           2      0\n",
       "120  0.801834  0.619879  0.109323           0      1\n",
       "121  0.212812  0.654493  0.676633           2      0\n",
       "130  0.130210  0.543792  0.883284           2      0\n",
       "134  0.570617  0.530557  0.397178           0      1\n",
       "136  0.226920  0.562646  0.760864           2      0\n",
       "137  0.113083  0.643764  0.842624           2      0\n",
       "138  0.206490  0.608781  0.751217           2      0\n",
       "147  0.786870  0.623125  0.114656           0      1\n",
       "149  0.203256  0.619344  0.731721           2      0\n",
       "150  0.345731  0.568992  0.616104           2      0\n",
       "152  0.206456  0.645359  0.669758           2      0\n",
       "153  0.895988  0.468779  0.099288           0      1\n",
       "155  0.163436  0.611702  0.787116           2      0\n",
       "157  0.750358  0.599545  0.154909           0      1\n",
       "158  0.645766  0.620944  0.219951           0      1\n",
       "159  0.737233  0.546542  0.209010           0      1"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TP + TN\n",
    "\n",
    "TP_TN = results_df[((results_df['prediction']==2) & (results_df['class']==0)) | (results_df['prediction']==0) & (results_df['class']==1)]\n",
    "print(len(TP_TN))\n",
    "TP_TN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "aa9894a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>prediction</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.106394</td>\n",
       "      <td>0.473036</td>\n",
       "      <td>0.935816</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.119603</td>\n",
       "      <td>0.655646</td>\n",
       "      <td>0.797179</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.214895</td>\n",
       "      <td>0.516755</td>\n",
       "      <td>0.818575</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.062248</td>\n",
       "      <td>0.673162</td>\n",
       "      <td>0.898006</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.152557</td>\n",
       "      <td>0.420727</td>\n",
       "      <td>0.931454</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.142046</td>\n",
       "      <td>0.640460</td>\n",
       "      <td>0.789578</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.128860</td>\n",
       "      <td>0.486328</td>\n",
       "      <td>0.911384</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.204479</td>\n",
       "      <td>0.652891</td>\n",
       "      <td>0.677987</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.040835</td>\n",
       "      <td>0.608336</td>\n",
       "      <td>0.955699</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.160816</td>\n",
       "      <td>0.628526</td>\n",
       "      <td>0.766817</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.361003</td>\n",
       "      <td>0.572152</td>\n",
       "      <td>0.585043</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.666177</td>\n",
       "      <td>0.608398</td>\n",
       "      <td>0.216563</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.100880</td>\n",
       "      <td>0.262390</td>\n",
       "      <td>0.984814</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>0.085207</td>\n",
       "      <td>0.548574</td>\n",
       "      <td>0.923385</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>0.168575</td>\n",
       "      <td>0.570042</td>\n",
       "      <td>0.824918</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>0.291435</td>\n",
       "      <td>0.579843</td>\n",
       "      <td>0.667896</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>0.684173</td>\n",
       "      <td>0.588062</td>\n",
       "      <td>0.224697</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>0.300980</td>\n",
       "      <td>0.583172</td>\n",
       "      <td>0.654454</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2  prediction  class\n",
       "6    0.106394  0.473036  0.935816           2      1\n",
       "7    0.119603  0.655646  0.797179           2      1\n",
       "8    0.214895  0.516755  0.818575           2      1\n",
       "21   0.062248  0.673162  0.898006           2      1\n",
       "43   0.152557  0.420727  0.931454           2      1\n",
       "46   0.142046  0.640460  0.789578           2      1\n",
       "47   0.128860  0.486328  0.911384           2      1\n",
       "63   0.204479  0.652891  0.677987           2      1\n",
       "65   0.040835  0.608336  0.955699           2      1\n",
       "68   0.160816  0.628526  0.766817           2      1\n",
       "83   0.361003  0.572152  0.585043           2      1\n",
       "97   0.666177  0.608398  0.216563           0      0\n",
       "100  0.100880  0.262390  0.984814           2      1\n",
       "116  0.085207  0.548574  0.923385           2      1\n",
       "127  0.168575  0.570042  0.824918           2      1\n",
       "133  0.291435  0.579843  0.667896           2      1\n",
       "140  0.684173  0.588062  0.224697           0      0\n",
       "160  0.300980  0.583172  0.654454           2      1"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CRITICAL MISSCLASSIFICTION (NEGATIVE AS POSITIVE OR POSITIE AS NEGATIVE)\n",
    "\n",
    "FP_FN = results_df[((results_df['prediction']==2) & (results_df['class']==1)) | (results_df['prediction']==0) & (results_df['class']==0)]\n",
    "print(len(FP_FN))\n",
    "FP_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fbdc1c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>prediction</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.506244</td>\n",
       "      <td>0.662116</td>\n",
       "      <td>0.307833</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.450417</td>\n",
       "      <td>0.779694</td>\n",
       "      <td>0.232185</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.630438</td>\n",
       "      <td>0.701516</td>\n",
       "      <td>0.162193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.497595</td>\n",
       "      <td>0.738499</td>\n",
       "      <td>0.249726</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.454631</td>\n",
       "      <td>0.765575</td>\n",
       "      <td>0.248944</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.520845</td>\n",
       "      <td>0.658625</td>\n",
       "      <td>0.312413</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.386938</td>\n",
       "      <td>0.600018</td>\n",
       "      <td>0.534007</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.528681</td>\n",
       "      <td>0.631339</td>\n",
       "      <td>0.328937</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.420527</td>\n",
       "      <td>0.726503</td>\n",
       "      <td>0.320084</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.369616</td>\n",
       "      <td>0.647212</td>\n",
       "      <td>0.492697</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.494137</td>\n",
       "      <td>0.818126</td>\n",
       "      <td>0.167224</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.058196</td>\n",
       "      <td>0.852220</td>\n",
       "      <td>0.730293</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.218838</td>\n",
       "      <td>0.761525</td>\n",
       "      <td>0.533851</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.114406</td>\n",
       "      <td>0.743255</td>\n",
       "      <td>0.723973</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.510592</td>\n",
       "      <td>0.535730</td>\n",
       "      <td>0.452863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.362472</td>\n",
       "      <td>0.798186</td>\n",
       "      <td>0.296027</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.490750</td>\n",
       "      <td>0.574472</td>\n",
       "      <td>0.431437</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.660620</td>\n",
       "      <td>0.708978</td>\n",
       "      <td>0.150856</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.496292</td>\n",
       "      <td>0.631103</td>\n",
       "      <td>0.356903</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.580297</td>\n",
       "      <td>0.779387</td>\n",
       "      <td>0.167452</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.430428</td>\n",
       "      <td>0.690918</td>\n",
       "      <td>0.344257</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.284603</td>\n",
       "      <td>0.650462</td>\n",
       "      <td>0.550513</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.474897</td>\n",
       "      <td>0.647570</td>\n",
       "      <td>0.354517</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.571181</td>\n",
       "      <td>0.626966</td>\n",
       "      <td>0.272477</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.472083</td>\n",
       "      <td>0.719952</td>\n",
       "      <td>0.270909</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.547794</td>\n",
       "      <td>0.656150</td>\n",
       "      <td>0.277932</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.214187</td>\n",
       "      <td>0.730482</td>\n",
       "      <td>0.559280</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.512177</td>\n",
       "      <td>0.618285</td>\n",
       "      <td>0.348587</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.346446</td>\n",
       "      <td>0.629348</td>\n",
       "      <td>0.530481</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.315162</td>\n",
       "      <td>0.651687</td>\n",
       "      <td>0.532742</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.302342</td>\n",
       "      <td>0.723899</td>\n",
       "      <td>0.477623</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.418879</td>\n",
       "      <td>0.625357</td>\n",
       "      <td>0.446357</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>0.419725</td>\n",
       "      <td>0.590305</td>\n",
       "      <td>0.509415</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>0.487879</td>\n",
       "      <td>0.583399</td>\n",
       "      <td>0.430873</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0.612210</td>\n",
       "      <td>0.629653</td>\n",
       "      <td>0.249202</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>0.526932</td>\n",
       "      <td>0.717116</td>\n",
       "      <td>0.242140</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>0.077155</td>\n",
       "      <td>0.785617</td>\n",
       "      <td>0.738134</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>0.335141</td>\n",
       "      <td>0.670979</td>\n",
       "      <td>0.467193</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>0.186045</td>\n",
       "      <td>0.733934</td>\n",
       "      <td>0.612963</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>0.487735</td>\n",
       "      <td>0.728894</td>\n",
       "      <td>0.257405</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.514855</td>\n",
       "      <td>0.658456</td>\n",
       "      <td>0.310629</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>0.334843</td>\n",
       "      <td>0.637730</td>\n",
       "      <td>0.509570</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>0.293133</td>\n",
       "      <td>0.667073</td>\n",
       "      <td>0.543017</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>0.188431</td>\n",
       "      <td>0.720565</td>\n",
       "      <td>0.639338</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>0.387661</td>\n",
       "      <td>0.613744</td>\n",
       "      <td>0.506824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>0.385944</td>\n",
       "      <td>0.786850</td>\n",
       "      <td>0.262818</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>0.417676</td>\n",
       "      <td>0.657783</td>\n",
       "      <td>0.399362</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.558818</td>\n",
       "      <td>0.601313</td>\n",
       "      <td>0.335876</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>0.186642</td>\n",
       "      <td>0.719079</td>\n",
       "      <td>0.633878</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>0.549895</td>\n",
       "      <td>0.647247</td>\n",
       "      <td>0.288493</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.444478</td>\n",
       "      <td>0.615166</td>\n",
       "      <td>0.446318</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0.470541</td>\n",
       "      <td>0.567979</td>\n",
       "      <td>0.473959</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>0.247602</td>\n",
       "      <td>0.712632</td>\n",
       "      <td>0.533438</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2  prediction  class\n",
       "2    0.506244  0.662116  0.307833           1      1\n",
       "4    0.450417  0.779694  0.232185           1      1\n",
       "11   0.630438  0.701516  0.162193           1      1\n",
       "12   0.497595  0.738499  0.249726           1      1\n",
       "14   0.454631  0.765575  0.248944           1      1\n",
       "15   0.520845  0.658625  0.312413           1      1\n",
       "17   0.386938  0.600018  0.534007           1      1\n",
       "19   0.528681  0.631339  0.328937           1      1\n",
       "24   0.420527  0.726503  0.320084           1      1\n",
       "27   0.369616  0.647212  0.492697           1      1\n",
       "28   0.494137  0.818126  0.167224           1      1\n",
       "30   0.058196  0.852220  0.730293           1      1\n",
       "32   0.218838  0.761525  0.533851           1      1\n",
       "33   0.114406  0.743255  0.723973           1      1\n",
       "34   0.510592  0.535730  0.452863           1      1\n",
       "37   0.362472  0.798186  0.296027           1      1\n",
       "39   0.490750  0.574472  0.431437           1      1\n",
       "40   0.660620  0.708978  0.150856           1      1\n",
       "53   0.496292  0.631103  0.356903           1      1\n",
       "54   0.580297  0.779387  0.167452           1      1\n",
       "57   0.430428  0.690918  0.344257           1      1\n",
       "59   0.284603  0.650462  0.550513           1      1\n",
       "61   0.474897  0.647570  0.354517           1      1\n",
       "64   0.571181  0.626966  0.272477           1      1\n",
       "74   0.472083  0.719952  0.270909           1      1\n",
       "79   0.547794  0.656150  0.277932           1      1\n",
       "80   0.214187  0.730482  0.559280           1      1\n",
       "86   0.512177  0.618285  0.348587           1      1\n",
       "88   0.346446  0.629348  0.530481           1      1\n",
       "89   0.315162  0.651687  0.532742           1      1\n",
       "90   0.302342  0.723899  0.477623           1      1\n",
       "98   0.418879  0.625357  0.446357           1      1\n",
       "105  0.419725  0.590305  0.509415           1      1\n",
       "109  0.487879  0.583399  0.430873           1      1\n",
       "111  0.612210  0.629653  0.249202           1      1\n",
       "112  0.526932  0.717116  0.242140           1      1\n",
       "113  0.077155  0.785617  0.738134           1      1\n",
       "114  0.335141  0.670979  0.467193           1      1\n",
       "119  0.186045  0.733934  0.612963           1      1\n",
       "122  0.487735  0.728894  0.257405           1      1\n",
       "123  0.514855  0.658456  0.310629           1      1\n",
       "125  0.334843  0.637730  0.509570           1      1\n",
       "128  0.293133  0.667073  0.543017           1      1\n",
       "131  0.188431  0.720565  0.639338           1      1\n",
       "132  0.387661  0.613744  0.506824           1      1\n",
       "139  0.385944  0.786850  0.262818           1      1\n",
       "141  0.417676  0.657783  0.399362           1      1\n",
       "142  0.558818  0.601313  0.335876           1      1\n",
       "143  0.186642  0.719079  0.633878           1      1\n",
       "144  0.549895  0.647247  0.288493           1      1\n",
       "145  0.444478  0.615166  0.446318           1      1\n",
       "154  0.470541  0.567979  0.473959           1      1\n",
       "156  0.247602  0.712632  0.533438           1      1"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# NEGATIVE AS NEUTRAL\n",
    "\n",
    "NN = results_df[(results_df['prediction']==1) & (results_df['class']==1)]\n",
    "print(len(NN))\n",
    "NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "4abaed95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>prediction</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.410257</td>\n",
       "      <td>0.632319</td>\n",
       "      <td>0.449694</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.394731</td>\n",
       "      <td>0.575934</td>\n",
       "      <td>0.563481</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.271917</td>\n",
       "      <td>0.651843</td>\n",
       "      <td>0.589307</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.420829</td>\n",
       "      <td>0.616327</td>\n",
       "      <td>0.451394</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.302612</td>\n",
       "      <td>0.645349</td>\n",
       "      <td>0.556045</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.617825</td>\n",
       "      <td>0.620355</td>\n",
       "      <td>0.262060</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.539422</td>\n",
       "      <td>0.608491</td>\n",
       "      <td>0.342120</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.534162</td>\n",
       "      <td>0.733605</td>\n",
       "      <td>0.216952</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.520257</td>\n",
       "      <td>0.663518</td>\n",
       "      <td>0.297561</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.415113</td>\n",
       "      <td>0.572961</td>\n",
       "      <td>0.513424</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.563345</td>\n",
       "      <td>0.640536</td>\n",
       "      <td>0.288438</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.481703</td>\n",
       "      <td>0.581242</td>\n",
       "      <td>0.450217</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.495118</td>\n",
       "      <td>0.578003</td>\n",
       "      <td>0.431095</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.494454</td>\n",
       "      <td>0.649303</td>\n",
       "      <td>0.337567</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.526748</td>\n",
       "      <td>0.584097</td>\n",
       "      <td>0.375792</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>0.579312</td>\n",
       "      <td>0.606392</td>\n",
       "      <td>0.317691</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>0.438328</td>\n",
       "      <td>0.697743</td>\n",
       "      <td>0.346783</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>0.282169</td>\n",
       "      <td>0.755284</td>\n",
       "      <td>0.444138</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>0.277681</td>\n",
       "      <td>0.691491</td>\n",
       "      <td>0.552361</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.281203</td>\n",
       "      <td>0.720784</td>\n",
       "      <td>0.483260</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.241451</td>\n",
       "      <td>0.724853</td>\n",
       "      <td>0.528179</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>0.356293</td>\n",
       "      <td>0.661653</td>\n",
       "      <td>0.475435</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1         2  prediction  class\n",
       "9    0.410257  0.632319  0.449694           1      0\n",
       "10   0.394731  0.575934  0.563481           1      0\n",
       "22   0.271917  0.651843  0.589307           1      0\n",
       "25   0.420829  0.616327  0.451394           1      0\n",
       "38   0.302612  0.645349  0.556045           1      0\n",
       "41   0.617825  0.620355  0.262060           1      0\n",
       "44   0.539422  0.608491  0.342120           1      0\n",
       "50   0.534162  0.733605  0.216952           1      0\n",
       "58   0.520257  0.663518  0.297561           1      0\n",
       "67   0.415113  0.572961  0.513424           1      0\n",
       "77   0.563345  0.640536  0.288438           1      0\n",
       "91   0.481703  0.581242  0.450217           1      0\n",
       "93   0.495118  0.578003  0.431095           1      0\n",
       "95   0.494454  0.649303  0.337567           1      0\n",
       "99   0.526748  0.584097  0.375792           1      0\n",
       "124  0.579312  0.606392  0.317691           1      0\n",
       "126  0.438328  0.697743  0.346783           1      0\n",
       "129  0.282169  0.755284  0.444138           1      0\n",
       "135  0.277681  0.691491  0.552361           1      0\n",
       "146  0.281203  0.720784  0.483260           1      0\n",
       "148  0.241451  0.724853  0.528179           1      0\n",
       "151  0.356293  0.661653  0.475435           1      0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POSITIVE AS NEUTRAL\n",
    "\n",
    "PN = results_df[(results_df['prediction']==1) & (results_df['class']==0)]\n",
    "print(len(PN))\n",
    "PN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f00e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
